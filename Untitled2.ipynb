{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx-mgEDVac8U"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "# import tensorflow as tf\n",
        "# import torch\n",
        "\n",
        "#Snake Game Using turtle\n",
        "\n",
        "### Snake Class\n",
        "\n",
        "# import required modules\n",
        "import turtle\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "\n",
        "HEIGHT = 20      # number of steps vertically from wall to wall of screen\n",
        "WIDTH = 20       # number of steps horizontally from wall to wall of screen\n",
        "\n",
        "    \n",
        "class Snake():\n",
        "    \n",
        "    \n",
        "    def __init__(self, human=False, env_info={'state_space':'coordinates'}):\n",
        "    \n",
        "        self.delay = 0.1\n",
        "        self.high_score = 0\n",
        "        self.segments = []\n",
        "        self.dist = 100\n",
        "        \n",
        "\n",
        "    # Creating a window screen\n",
        "        self.wn = turtle.Screen()\n",
        "        self.wn.title(\"Snake Game\")\n",
        "        self.wn.bgcolor(\"white\")\n",
        "        # the width and height can be put as user's choice\n",
        "        self.wn.setup(width=600, height=600)\n",
        "        self.wn.tracer(0)\n",
        "\n",
        "        self.done = False\n",
        "#         self.seed()\n",
        "        self.reward = 0\n",
        "        self.action_space = 4\n",
        "        self.state_space = 12\n",
        "\n",
        "        self.total, self.maximum = 0, 0\n",
        "        self.human = human\n",
        "        self.env_info = env_info\n",
        "        \n",
        "        # head of the snake\n",
        "        self.head = turtle.Turtle()\n",
        "        self.head.shape(\"square\")\n",
        "        self.head.color(\"black\")\n",
        "        self.head.penup()\n",
        "        self.head.goto(0, 0)\n",
        "        self.head.direction = \"Stop\"\n",
        "        \n",
        "        self.head_body = []\n",
        "        self.add_to_body()\n",
        "\n",
        "        # food in the game\n",
        "        self.food = turtle.Turtle()\n",
        "        self.food.speed(0)\n",
        "        self.food.shape('circle')\n",
        "        self.food.color('red')\n",
        "        self.food.penup()\n",
        "        self.food.goto(0, 100)\n",
        "\n",
        "        self.pen = turtle.Turtle()\n",
        "        self.pen.speed(0)\n",
        "        self.pen.shape(\"square\")\n",
        "        self.pen.color(\"black\")\n",
        "        self.pen.penup()\n",
        "        self.pen.hideturtle()\n",
        "        self.pen.goto(0, 250)\n",
        "        self.pen.write(\"Score : 0  High Score : 0\", align=\"center\",\n",
        "                  font=(\"candara\", 24, \"bold\"))\n",
        "    \n",
        "\n",
        "        self.wn.listen()\n",
        "        self.wn.onkey(self.go_up, 'Up')\n",
        "        self.wn.onkey(self.go_right, 'Right')\n",
        "        self.wn.onkey(self.go_down, 'Down')\n",
        "        self.wn.onkey(self.go_left, 'Left')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     def seed(self, seed=None):\n",
        "#         self.np_random, seed = seeding.np_random(seed)\n",
        "#         return [seed]\n",
        "\n",
        "    def random_coordinates(self):\n",
        "        food_x = random.randint(-WIDTH/2, WIDTH/2)\n",
        "        food_y = random.randint(-HEIGHT/2, HEIGHT/2)\n",
        "        return food_x, food_y\n",
        "    \n",
        "    def move_head(self):\n",
        "        if self.head.direction == 'stop':\n",
        "            self.reward = 0\n",
        "        if self.head.direction == 'up':\n",
        "            y = self.head.ycor()\n",
        "            self.head.sety(y + 20)\n",
        "        if self.head.direction == 'right':\n",
        "            x = self.head.xcor()\n",
        "            self.head.setx(x + 20)\n",
        "        if self.head.direction == 'down':\n",
        "            y = self.head.ycor()\n",
        "            self.head.sety(y - 20)\n",
        "        if self.head.direction == 'left':\n",
        "            x = self.head.xcor()\n",
        "            self.head.setx(x - 20)\n",
        "        \n",
        "    \n",
        "    def go_up(self):\n",
        "        if self.head.direction != \"down\":\n",
        "            self.head.direction = \"up\"\n",
        "    \n",
        "    \n",
        "    def go_down(self):\n",
        "        if self.head.direction != \"up\":\n",
        "            self.head.direction = \"down\"\n",
        "    \n",
        "    \n",
        "    def go_right(self):\n",
        "        if self.head.direction != \"left\":\n",
        "            self.head.direction = \"right\"\n",
        "    \n",
        "    \n",
        "    def go_left(self):\n",
        "        if self.head.direction != \"right\":\n",
        "            self.head.direction = \"left\"\n",
        "\n",
        "\n",
        "    def move_food(self, first=False):\n",
        "        if first or self.head.distance(self.food) < 20:    \n",
        "            while True:\n",
        "                self.food.x, self.food.y = self.random_coordinates()\n",
        "                self.food.goto(round(self.food.x*20), round(self.food.y*20))\n",
        "                self.dist = math.sqrt((self.head.xcor()-self.food.xcor())**2 + (self.head.ycor()-self.food.ycor())**2)\n",
        "                if not self.body_check_food():\n",
        "                    break\n",
        "            if not first:\n",
        "                self.update_score()\n",
        "                self.add_to_body()\n",
        "            first = False\n",
        "            return True\n",
        "\n",
        "\n",
        "\n",
        "    def update_score(self):\n",
        "        self.total += 1\n",
        "        if self.total >= self.maximum:\n",
        "            self.maximum = self.total\n",
        "        self.pen.clear()\n",
        "        self.pen.write(f\"Total: {self.total}   Highest: {self.maximum}\", align='center', font=('Courier', 18, 'normal'))\n",
        "\n",
        "\n",
        "    def reset_score(self):\n",
        "        self.pen.clear()\n",
        "        self.total = 0\n",
        "        self.pen.write(f\"Total: {self.total}   Highest: {self.maximum}\", align='center', font=('Courier', 18, 'normal'))\n",
        "                    \n",
        "\n",
        "    def add_to_body(self):\n",
        "        body = turtle.Turtle()\n",
        "        body.speed(0)\n",
        "        body.shape('square')\n",
        "        body.color('black')\n",
        "        body.penup()\n",
        "        self.head_body.append(body)\n",
        "        \n",
        "\n",
        "    def move_headbody(self):\n",
        "      if len(self.head_body) > 0:\n",
        "          for index in range(len(self.head_body)-1, 0, -1):\n",
        "              x = self.head_body[index-1].xcor()\n",
        "              y = self.head_body[index-1].ycor()\n",
        "              self.head_body[index].goto(x, y)\n",
        "\n",
        "          self.head_body[0].goto(self.head.xcor(), self.head.ycor())\n",
        "        \n",
        "    \n",
        "    def measure_distance(self):\n",
        "      self.prev_dist = self.dist\n",
        "      self.dist = math.sqrt((self.head.xcor()-self.food.xcor())**2 + (self.head.ycor()-self.food.ycor())**2)\n",
        "\n",
        "\n",
        "    def body_hit(self):\n",
        "      if len(self.head_body) > 1:\n",
        "          for body in self.head_body[1:]:\n",
        "              if body.distance(self.head) < 20:\n",
        "                  self.reset_score()\n",
        "                  return True     \n",
        "\n",
        "    def body_check_food(self):\n",
        "      if len(self.head_body) > 0:\n",
        "          for body in self.head_body[:]:\n",
        "              if body.distance(self.food) < 20:\n",
        "                  return True\n",
        "\n",
        "    def wall_hit(self):\n",
        "      if self.head.xcor() > 200 or self.head.xcor() < -200 or self.head.ycor() > 200 or self.head.ycor() < -200:\n",
        "          self.reset_score()\n",
        "          return True\n",
        "    \n",
        "    def reset(self):\n",
        "      if self.human:\n",
        "          time.sleep(1)\n",
        "#       self.head_body.clear()\n",
        "      for body in self.head_body:\n",
        "          body.goto(1000, 1000)\n",
        "\n",
        "      self.head_body = []\n",
        "      self.head.goto(0,0)\n",
        "      self.head.direction = 'stop'\n",
        "      self.reward = 0\n",
        "      self.total = 0\n",
        "      self.done = False\n",
        "\n",
        "      state = self.get_state()\n",
        "\n",
        "      return state\n",
        "\n",
        "\n",
        "    def run_game(self):\n",
        "      reward_given = False\n",
        "      self.wn.update()\n",
        "      self.move_head()\n",
        "      if self.move_food():\n",
        "          self.reward = 10\n",
        "          reward_given = True\n",
        "\n",
        "      self.move_headbody()\n",
        "      self.measure_distance()\n",
        "\n",
        "      if self.body_hit():\n",
        "          self.reward = -100\n",
        "          reward_given = True\n",
        "          self.done = True\n",
        "          if self.human:\n",
        "              self.reset()\n",
        "\n",
        "      if self.wall_hit():\n",
        "          self.reward = -100\n",
        "          reward_given = True\n",
        "          self.done = True\n",
        "          if self.human:\n",
        "              self.reset()\n",
        "\n",
        "      if not reward_given:\n",
        "          if self.dist < self.prev_dist:\n",
        "              self.reward = 1\n",
        "          else:\n",
        "              self.reward = -1\n",
        "      time.sleep(0.005)\n",
        "      if self.human:\n",
        "          time.sleep(0.2)\n",
        "          state = self.get_state()\n",
        "\n",
        "    \n",
        "    # AI agent\n",
        "    def step(self, action):\n",
        "      if action == 0:\n",
        "          self.go_up()\n",
        "      if action == 1:\n",
        "          self.go_right()\n",
        "      if action == 2:\n",
        "          self.go_left()\n",
        "      if action == 3:\n",
        "          self.go_down()\n",
        "      self.run_game()\n",
        "      state = self.get_state()\n",
        "      return state, self.reward, self.done\n",
        "\n",
        "\n",
        "    def get_state(self):\n",
        "      # head coordinates abs\n",
        "      self.head.x, self.head.y = self.head.xcor()/WIDTH, self.head.ycor()/HEIGHT\n",
        "      # food coordinates abs\n",
        "      self.food.x, self.food.y = self.food.xcor()/WIDTH, self.food.ycor()/HEIGHT\n",
        "      # head coordinates scaled 0-1\n",
        "      self.head.xsc, self.head.ysc = self.head.x/WIDTH+0.5, self.head.y/HEIGHT+0.5\n",
        "      # food coordintes scaled 0-1 \n",
        "      self.food.xsc, self.food.ysc = self.food.x/WIDTH+0.5, self.food.y/HEIGHT+0.5\n",
        "\n",
        "      # wall check\n",
        "      if self.head.y >= HEIGHT/2:\n",
        "          wall_up, wall_down = 1, 0\n",
        "      elif self.head.y <= -HEIGHT/2:\n",
        "          wall_up, wall_down = 0, 1\n",
        "      else:\n",
        "          wall_up, wall_down = 0, 0\n",
        "      if self.head.x >= WIDTH/2:\n",
        "          wall_right, wall_left = 1, 0\n",
        "      elif self.head.x <= -WIDTH/2:\n",
        "          wall_right, wall_left = 0, 1\n",
        "      else:\n",
        "          wall_right, wall_left = 0, 0\n",
        "\n",
        "      # body close\n",
        "      body_up = []\n",
        "      body_right = []\n",
        "      body_down = []\n",
        "      body_left = []\n",
        "      if len(self.head_body) > 3:\n",
        "          for body in self.head_body[3:]:\n",
        "              if body.distance(self.head) == 20:\n",
        "                  if body.ycor() < self.head.ycor():\n",
        "                      body_down.append(1)\n",
        "                  elif body.ycor() > self.head.ycor():\n",
        "                      body_up.append(1)\n",
        "                  if body.xcor() < self.head.xcor():\n",
        "                      body_left.append(1)\n",
        "                  elif body.xcor() > self.head.xcor():\n",
        "                      body_right.append(1)\n",
        "      \n",
        "      if len(body_up) > 0: body_up = 1\n",
        "      else: body_up = 0\n",
        "      if len(body_right) > 0: body_right = 1\n",
        "      else: body_right = 0\n",
        "      if len(body_down) > 0: body_down = 1\n",
        "      else: body_down = 0\n",
        "      if len(body_left) > 0: body_left = 1\n",
        "      else: body_left = 0\n",
        "\n",
        "      # state: food_up, food_right, food_down, food_left, obstacle_up, obstacle_right, obstacle_down, obstacle_left, direction_up, direction_right, direction_down, direction_left\n",
        "      if self.env_info['state_space'] == 'coordinates':\n",
        "          state = [self.food.xsc, self.food.ysc, self.head.xsc, self.head.ysc, \\\n",
        "                  int(wall_up or body_up), int(wall_right or body_right), int(wall_down or body_down), int(wall_left or body_left), \\\n",
        "                  int(self.head.direction == 'up'), int(self.head.direction == 'right'), int(self.head.direction == 'down'), int(self.head.direction == 'left')]\n",
        "      elif self.env_info['state_space'] == 'no direction':\n",
        "          state = [int(self.head.y < self.food.y), int(self.head.x < self.food.x), int(self.head.y > self.food.y), int(self.head.x > self.food.x), \\\n",
        "                  int(wall_up or body_up), int(wall_right or body_right), int(wall_down or body_down), int(wall_left or body_left), \\\n",
        "                  0, 0, 0, 0]\n",
        "      elif self.env_info['state_space'] == 'no body knowledge':\n",
        "          state = [int(self.head.y < self.food.y), int(self.head.x < self.food.x), int(self.head.y > self.food.y), int(self.head.x > self.food.x), \\\n",
        "                  wall_up, wall_right, wall_down, wall_left, \\\n",
        "                  int(self.head.direction == 'up'), int(self.head.direction == 'right'), int(self.head.direction == 'down'), int(self.head.direction == 'left')]\n",
        "      else:\n",
        "          state = [int(self.head.y < self.food.y), int(self.head.x < self.food.x), int(self.head.y > self.food.y), int(self.head.x > self.food.x), \\\n",
        "                  int(wall_up or body_up), int(wall_right or body_right), int(wall_down or body_down), int(wall_left or body_left), \\\n",
        "                  int(self.head.direction == 'up'), int(self.head.direction == 'right'), int(self.head.direction == 'down'), int(self.head.direction == 'left')]\n",
        "          \n",
        "      # print(state)\n",
        "      return state\n",
        "\n",
        "    def bye(self):\n",
        "        self.wn.bye()\n",
        "\n",
        "\n",
        "\n",
        "from keras import Sequential\n",
        "from collections import deque\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Adam\n",
        "import time\n",
        "\n",
        "class DQN:\n",
        "\n",
        "  \"\"\" Deep Q Network \"\"\"\n",
        "\n",
        "  def __init__(self, env, params):\n",
        "\n",
        "      self.action_space = env.action_space\n",
        "      self.state_space = env.state_space\n",
        "      self.epsilon = params['epsilon']                  # epsilon greedy exploration\n",
        "      self.gamma = params['gamma']                      # discount factor\n",
        "      self.batch_size = params['batch_size']            # experience replay batch size\n",
        "      self.epsilon_min = params['epsilon_min']          # min greedininess\n",
        "      self.epsilon_decay = params['epsilon_decay']      # decay factor for exploration\n",
        "      self.learning_rate = params['learning_rate']      # NN learning rate\n",
        "      self.layer_sizes = params['layer_sizes']          # NN architecture\n",
        "      self.memory = deque(maxlen=2500)                  # maximum memory for experinece replay\n",
        "      self.model = self.build_model()                   \n",
        "\n",
        "\n",
        "  def build_model(self):\n",
        "      model = Sequential()\n",
        "      for i in range(len(self.layer_sizes)):\n",
        "          if i == 0:\n",
        "              model.add(Dense(self.layer_sizes[i], input_shape=(self.state_space,), activation='relu'))\n",
        "          else:\n",
        "              model.add(Dense(self.layer_sizes[i], activation='relu'))\n",
        "      model.add(Dense(self.action_space, activation='softmax'))\n",
        "      model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
        "      return model\n",
        "\n",
        "\n",
        "  def remember(self, state, action, reward, next_state, done):\n",
        "    # create dataet for xperience replay\n",
        "      self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "\n",
        "  def act(self, state):\n",
        "      #  epsilon greedy policy\n",
        "      if np.random.rand() <= self.epsilon:\n",
        "          return random.randrange(self.action_space)\n",
        "      act_values = self.model.predict(state)\n",
        "      return np.argmax(act_values[0])\n",
        "\n",
        "\n",
        "  def exp_replay(self):\n",
        "    if len(self.memory)<self.batch_size:\n",
        "      return \n",
        "    minibatch = random.sample(self.memory, self.batch_size)\n",
        "    states = np.array([i[0] for i in minibatch])\n",
        "    actions = np.array([i[1] for i in minibatch])\n",
        "    rewards = np.array([i[2] for i in minibatch])\n",
        "    next_states = np.array([i[3] for i in minibatch])\n",
        "    dones = np.array([i[4] for i in minibatch])\n",
        "    \n",
        "    states = np.squeeze(states)\n",
        "    next_states = np.squeeze(next_states)\n",
        "\n",
        "    targets_pred = self.model.predict_on_batch(states)\n",
        "    targets_act = rewards + self.gamma*((np.amax(self.model.predict_on_batch(next_states), axis=1))*(1-dones))\n",
        "\n",
        "    ind = np.array([i for i in range(self.batch_size)])\n",
        "    targets_full = targets_pred\n",
        "    targets_full[[ind], [actions]] = targets_act\n",
        "\n",
        "    self.model.fit(states, targets_full, epochs=1, verbose=0)\n",
        "    if self.epsilon > self.epsilon_min:\n",
        "        self.epsilon *= self.epsilon_decay\n",
        "\n",
        "\n",
        "def learning(env,episodes, params):\n",
        "\n",
        "  sum_of_rewards = []\n",
        "  agent = DQN(env, params)\n",
        "  for ep in range(episodes):\n",
        "      state = env.reset()\n",
        "      state = np.reshape(state, (1, env.state_space))\n",
        "      score = 0\n",
        "      max_steps = 100000\n",
        "      for i in range(max_steps):\n",
        "          action = agent.act(state)\n",
        "          next_state, reward, done = env.step(action)\n",
        "          score += reward\n",
        "          next_state = np.reshape(next_state, (1, env.state_space))\n",
        "          agent.remember(state, action, reward, next_state, done)\n",
        "          if params['batch_size'] > 1:\n",
        "              agent.exp_replay()\n",
        "          if done:\n",
        "              print(f'final state before dying: {str(state)}')\n",
        "              print(f'episode: {ep+1}/{episodes}, score: {score}')\n",
        "              break\n",
        "          state = next_state\n",
        "      sum_of_rewards.append(score)\n",
        "  env.bye()\n",
        "  return sum_of_rewards\n",
        "\n",
        "\n",
        "params = dict()\n",
        "params['name'] = None\n",
        "params['epsilon'] = 1\n",
        "params['gamma'] = .95\n",
        "params['batch_size'] = 500\n",
        "params['epsilon_min'] = .01\n",
        "params['epsilon_decay'] = .995\n",
        "params['learning_rate'] = 0.00025\n",
        "params['layer_sizes'] = [128, 128, 128]\n",
        "\n",
        "results = dict()\n",
        "ep = 50\n",
        "\n",
        "\n",
        "env_infos = {'States: only walls':{'state_space':'no body knowledge'}, 'States: direction 0 or 1':{'state_space':''}, 'States: coordinates':{'state_space':'coordinates'}, 'States: no direction':{'state_space':'no direction'}}\n",
        "\n",
        "env = Snake()\n",
        "sum_of_rewards = learning(env, ep, params)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
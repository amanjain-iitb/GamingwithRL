{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0J0c5RiPyyjX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shubh\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Bp_Qw6w6ziW0"
   },
   "outputs": [],
   "source": [
    "output = []\n",
    "env = gym.make('MsPacman-ram-v0')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    output.append(env.render(mode = 'rgb_array'))\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "NoZyIGnVB9rU",
    "outputId": "ce6f2df7-98ba-4ba0-9bd5-0c7627ecc650"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a473352148>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(output[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtALAlmU8itC",
    "outputId": "a183efcd-3706-428e-b13a-7c6a0506513e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 1/2000, score: 280.0, rewards : -1505.0\n",
      "0.9972537640739171\n",
      "episode: 2/2000, score: 210.0, rewards : -1402.0\n",
      "0.9911592667463877\n",
      "episode: 3/2000, score: 610.0, rewards : -1259.0\n",
      "0.9825735402619077\n",
      "episode: 4/2000, score: 580.0, rewards : -1350.0\n",
      "0.9734681862663941\n",
      "episode: 5/2000, score: 190.0, rewards : -1449.0\n",
      "0.967257853086803\n",
      "episode: 6/2000, score: 240.0, rewards : -1472.0\n",
      "0.9603857982225352\n",
      "episode: 7/2000, score: 230.0, rewards : -1431.0\n",
      "0.9540490104640773\n",
      "episode: 8/2000, score: 180.0, rewards : -1531.0\n",
      "0.9472802729662283\n",
      "episode: 9/2000, score: 180.0, rewards : -1386.0\n",
      "0.9419243653858843\n",
      "episode: 10/2000, score: 290.0, rewards : -1466.0\n",
      "0.9348208830253738\n",
      "episode: 11/2000, score: 260.0, rewards : -1418.0\n",
      "0.9284949185536767\n",
      "episode: 12/2000, score: 220.0, rewards : -1517.0\n",
      "0.9216678149179246\n",
      "episode: 13/2000, score: 260.0, rewards : -1486.0\n",
      "0.9148085732081574\n",
      "episode: 14/2000, score: 160.0, rewards : -1484.0\n",
      "0.9089270169129214\n",
      "episode: 15/2000, score: 200.0, rewards : -1475.0\n",
      "0.9028033609372833\n",
      "episode: 16/2000, score: 310.0, rewards : -1352.0\n",
      "0.8968375433637458\n",
      "episode: 17/2000, score: 370.0, rewards : -1675.0\n",
      "0.8875054678414431\n",
      "episode: 18/2000, score: 350.0, rewards : -1605.0\n",
      "0.8790613007786999\n",
      "episode: 19/2000, score: 260.0, rewards : -1609.0\n",
      "0.8714466013607621\n",
      "episode: 20/2000, score: 190.0, rewards : -1362.0\n",
      "0.866640777975018\n",
      "episode: 21/2000, score: 270.0, rewards : -1419.0\n",
      "0.8606815099288818\n",
      "episode: 22/2000, score: 960.0, rewards : -1012.0\n",
      "0.8523476471597727\n",
      "episode: 23/2000, score: 290.0, rewards : -1479.0\n",
      "0.8458097408292929\n",
      "episode: 24/2000, score: 270.0, rewards : -1323.0\n",
      "0.8408004981021763\n",
      "episode: 25/2000, score: 270.0, rewards : -1348.0\n",
      "0.8356119920695595\n",
      "episode: 26/2000, score: 230.0, rewards : -1459.0\n",
      "0.8298660867650064\n",
      "episode: 27/2000, score: 260.0, rewards : -1455.0\n",
      "0.8239454371998525\n",
      "episode: 28/2000, score: 230.0, rewards : -1311.0\n",
      "0.8194917111620647\n",
      "episode: 29/2000, score: 300.0, rewards : -1346.0\n",
      "0.8142066888492914\n",
      "episode: 30/2000, score: 250.0, rewards : -1468.0\n",
      "0.8083735090015878\n",
      "episode: 31/2000, score: 240.0, rewards : -1359.0\n",
      "0.8035377655066218\n",
      "episode: 32/2000, score: 200.0, rewards : -1432.0\n",
      "0.7984674107024963\n",
      "episode: 33/2000, score: 340.0, rewards : -1548.0\n",
      "0.7914004592290398\n",
      "episode: 34/2000, score: 180.0, rewards : -1551.0\n",
      "0.7856285300415661\n",
      "episode: 35/2000, score: 310.0, rewards : -1433.0\n",
      "0.7798051146286541\n",
      "episode: 36/2000, score: 380.0, rewards : -1353.0\n",
      "0.7741022716106986\n",
      "episode: 37/2000, score: 320.0, rewards : -1441.0\n",
      "0.7682259999483082\n",
      "episode: 38/2000, score: 240.0, rewards : -1481.0\n",
      "0.7626993557888803\n",
      "episode: 39/2000, score: 270.0, rewards : -1562.0\n",
      "0.7563724267649025\n",
      "episode: 40/2000, score: 350.0, rewards : -1562.0\n",
      "0.749498141003354\n",
      "episode: 41/2000, score: 190.0, rewards : -1476.0\n",
      "0.7445155987409744\n",
      "episode: 42/2000, score: 260.0, rewards : -1477.0\n",
      "0.7390412713650572\n",
      "episode: 43/2000, score: 270.0, rewards : -1437.0\n",
      "0.7338273122889466\n",
      "episode: 44/2000, score: 320.0, rewards : -1698.0\n",
      "0.7263875447699484\n",
      "episode: 45/2000, score: 300.0, rewards : -1437.0\n",
      "0.7210465106417373\n",
      "episode: 46/2000, score: 580.0, rewards : -1534.0\n",
      "0.7130514573256825\n",
      "episode: 47/2000, score: 250.0, rewards : -1581.0\n",
      "0.707143451047459\n",
      "episode: 48/2000, score: 240.0, rewards : -1232.0\n",
      "0.7038065438463738\n",
      "episode: 49/2000, score: 230.0, rewards : -1421.0\n",
      "0.6992326294750707\n",
      "episode: 50/2000, score: 270.0, rewards : -1444.0\n",
      "0.6942509220928587\n",
      "episode: 51/2000, score: 180.0, rewards : -1501.0\n",
      "0.6895322162873723\n",
      "episode: 52/2000, score: 180.0, rewards : -1518.0\n",
      "0.68472916828955\n",
      "episode: 53/2000, score: 190.0, rewards : -1426.0\n",
      "0.6805173750060874\n",
      "episode: 54/2000, score: 240.0, rewards : -1377.0\n",
      "0.6763247252968906\n",
      "episode: 55/2000, score: 270.0, rewards : -1434.0\n",
      "0.6715733803971364\n",
      "episode: 56/2000, score: 360.0, rewards : -1651.0\n",
      "0.664811297826296\n",
      "episode: 57/2000, score: 310.0, rewards : -1534.0\n",
      "0.6592172823904658\n",
      "episode: 58/2000, score: 180.0, rewards : -1417.0\n",
      "0.6552869069252204\n",
      "episode: 59/2000, score: 530.0, rewards : -1450.0\n",
      "0.6488899388137851\n",
      "episode: 60/2000, score: 300.0, rewards : -1422.0\n",
      "0.6442153601480275\n",
      "episode: 61/2000, score: 290.0, rewards : -1389.0\n",
      "0.6398495345001307\n",
      "episode: 62/2000, score: 320.0, rewards : -1416.0\n",
      "0.635151154735253\n",
      "episode: 63/2000, score: 290.0, rewards : -1766.0\n",
      "0.628472930232244\n",
      "episode: 64/2000, score: 280.0, rewards : -1438.0\n",
      "0.6239703933682458\n",
      "episode: 65/2000, score: 340.0, rewards : -1504.0\n",
      "0.6187200313130045\n",
      "episode: 66/2000, score: 250.0, rewards : -1396.0\n",
      "0.6147298150285564\n",
      "episode: 67/2000, score: 920.0, rewards : -1117.0\n",
      "0.608381890533336\n",
      "episode: 68/2000, score: 310.0, rewards : -1680.0\n",
      "0.602382571724871\n",
      "episode: 69/2000, score: 410.0, rewards : -1296.0\n",
      "0.5981387253977223\n",
      "episode: 70/2000, score: 320.0, rewards : -1442.0\n",
      "0.593592270971083\n",
      "episode: 71/2000, score: 260.0, rewards : -1488.0\n",
      "0.5891628515976061\n",
      "episode: 72/2000, score: 270.0, rewards : -1525.0\n",
      "0.5844917077599846\n",
      "episode: 73/2000, score: 370.0, rewards : -1570.0\n",
      "0.5790174103826428\n",
      "episode: 74/2000, score: 230.0, rewards : -1540.0\n",
      "0.5745703294396897\n",
      "episode: 75/2000, score: 270.0, rewards : -1417.0\n",
      "0.570630833281972\n",
      "episode: 76/2000, score: 350.0, rewards : -1212.0\n",
      "0.5674271923836679\n",
      "episode: 77/2000, score: 280.0, rewards : -1505.0\n",
      "0.5629846744060819\n",
      "episode: 78/2000, score: 270.0, rewards : -1405.0\n",
      "0.5591917136936503\n",
      "episode: 79/2000, score: 240.0, rewards : -1410.0\n",
      "0.5555631811830024\n",
      "episode: 80/2000, score: 310.0, rewards : -1623.0\n",
      "0.5503983525428837\n",
      "episode: 81/2000, score: 220.0, rewards : -1470.0\n",
      "0.5466081910650445\n",
      "episode: 82/2000, score: 290.0, rewards : -1390.0\n",
      "0.5428984168533303\n",
      "episode: 83/2000, score: 230.0, rewards : -1480.0\n",
      "0.5390520798094292\n",
      "episode: 84/2000, score: 300.0, rewards : -1510.0\n",
      "0.5346980252279163\n",
      "episode: 85/2000, score: 240.0, rewards : -1439.0\n",
      "0.5310743948446195\n",
      "episode: 86/2000, score: 870.0, rewards : -1104.0\n",
      "0.5259215546469223\n",
      "episode: 87/2000, score: 300.0, rewards : -1401.0\n",
      "0.5222424955442965\n",
      "episode: 88/2000, score: 270.0, rewards : -1533.0\n",
      "0.5180604792034884\n",
      "episode: 89/2000, score: 310.0, rewards : -1303.0\n",
      "0.5148893174346593\n",
      "episode: 90/2000, score: 210.0, rewards : -1484.0\n",
      "0.5113232253722552\n",
      "episode: 91/2000, score: 250.0, rewards : -1357.0\n",
      "0.5082237964766134\n",
      "episode: 92/2000, score: 340.0, rewards : -1495.0\n",
      "0.503992734862652\n",
      "episode: 93/2000, score: 240.0, rewards : -1455.0\n",
      "0.5004971068465615\n",
      "episode: 94/2000, score: 180.0, rewards : -1515.0\n",
      "0.49702572405144546\n",
      "episode: 95/2000, score: 500.0, rewards : -1359.0\n",
      "0.4927696090703854\n",
      "episode: 96/2000, score: 280.0, rewards : -1393.0\n",
      "0.48945949297683244\n",
      "episode: 97/2000, score: 550.0, rewards : -1482.0\n",
      "0.4844293765451439\n",
      "episode: 98/2000, score: 220.0, rewards : -1461.0\n",
      "0.48113679220897826\n",
      "episode: 99/2000, score: 360.0, rewards : -1829.0\n",
      "0.47544516825217553\n",
      "episode: 100/2000, score: 220.0, rewards : -1512.0\n",
      "0.4719728792933827\n",
      "episode: 101/2000, score: 360.0, rewards : -1599.0\n",
      "0.46746359629553835\n",
      "episode: 102/2000, score: 280.0, rewards : -1518.0\n",
      "0.46374342543427743\n",
      "episode: 103/2000, score: 290.0, rewards : -1389.0\n",
      "0.4606006519674367\n",
      "episode: 104/2000, score: 210.0, rewards : -1526.0\n",
      "0.4572184868392192\n",
      "episode: 105/2000, score: 300.0, rewards : -1420.0\n",
      "0.453933780720556\n",
      "episode: 106/2000, score: 230.0, rewards : -1460.0\n",
      "0.45080789503934326\n",
      "episode: 107/2000, score: 390.0, rewards : -1532.0\n",
      "0.44666606142574666\n",
      "episode: 108/2000, score: 220.0, rewards : -1392.0\n",
      "0.4439363599037014\n",
      "episode: 109/2000, score: 300.0, rewards : -1694.0\n",
      "0.439541073955949\n",
      "episode: 110/2000, score: 260.0, rewards : -1472.0\n",
      "0.43633100112327283\n",
      "episode: 111/2000, score: 610.0, rewards : -1419.0\n",
      "0.4318598354878381\n",
      "episode: 112/2000, score: 500.0, rewards : -1609.0\n",
      "0.4270926741703835\n",
      "episode: 113/2000, score: 310.0, rewards : -1443.0\n",
      "0.42388448942196955\n",
      "episode: 114/2000, score: 260.0, rewards : -1454.0\n",
      "0.42086450951665055\n",
      "episode: 115/2000, score: 300.0, rewards : -1475.0\n",
      "0.4176112237306969\n",
      "episode: 116/2000, score: 250.0, rewards : -1423.0\n",
      "0.41480597436654193\n",
      "episode: 117/2000, score: 330.0, rewards : -1584.0\n",
      "0.411027792352875\n",
      "episode: 118/2000, score: 280.0, rewards : -1477.0\n",
      "0.4079239645364042\n",
      "episode: 119/2000, score: 310.0, rewards : -1414.0\n",
      "0.4049771960031072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 120/2000, score: 230.0, rewards : -1560.0\n",
      "0.4017864464799884\n",
      "episode: 121/2000, score: 260.0, rewards : -1391.0\n",
      "0.39917530735686185\n",
      "episode: 122/2000, score: 200.0, rewards : -1529.0\n",
      "0.3962719233413801\n",
      "episode: 123/2000, score: 250.0, rewards : -1489.0\n",
      "0.3933503197661591\n",
      "episode: 124/2000, score: 330.0, rewards : -1346.0\n",
      "0.39069631876148464\n",
      "episode: 125/2000, score: 290.0, rewards : -1624.0\n",
      "0.38713773500047527\n",
      "episode: 126/2000, score: 250.0, rewards : -1657.0\n",
      "0.3836384178123683\n",
      "episode: 127/2000, score: 320.0, rewards : -1380.0\n",
      "0.3809585031790283\n",
      "episode: 128/2000, score: 230.0, rewards : -1460.0\n",
      "0.37833514096013054\n",
      "episode: 129/2000, score: 260.0, rewards : -1345.0\n",
      "0.3760493515142094\n",
      "episode: 130/2000, score: 360.0, rewards : -1615.0\n",
      "0.37239694432187415\n",
      "episode: 131/2000, score: 180.0, rewards : -1567.0\n",
      "0.3696217933066643\n",
      "episode: 132/2000, score: 330.0, rewards : -1311.0\n",
      "0.3672564105697136\n",
      "episode: 133/2000, score: 250.0, rewards : -1518.0\n",
      "0.3644430260334791\n",
      "episode: 134/2000, score: 320.0, rewards : -1318.0\n",
      "0.36212164819136144\n",
      "episode: 135/2000, score: 260.0, rewards : -1955.0\n",
      "0.3577448916762807\n",
      "episode: 136/2000, score: 260.0, rewards : -1489.0\n",
      "0.35507182814167154\n",
      "episode: 137/2000, score: 240.0, rewards : -1415.0\n",
      "0.3527501687095101\n",
      "episode: 138/2000, score: 300.0, rewards : -1422.0\n",
      "0.35020896978753757\n",
      "episode: 139/2000, score: 380.0, rewards : -1534.0\n",
      "0.34701915741153117\n",
      "episode: 140/2000, score: 230.0, rewards : -1363.0\n",
      "0.3449639633099236\n",
      "episode: 141/2000, score: 230.0, rewards : -1659.0\n",
      "0.3419073906778039\n",
      "episode: 142/2000, score: 250.0, rewards : -1541.0\n",
      "0.3392101657671375\n",
      "episode: 143/2000, score: 220.0, rewards : -1376.0\n",
      "0.33719110387871903\n",
      "episode: 144/2000, score: 230.0, rewards : -1503.0\n",
      "0.3347251698954739\n",
      "episode: 145/2000, score: 410.0, rewards : -1723.0\n",
      "0.3309508086724764\n",
      "episode: 146/2000, score: 270.0, rewards : -1425.0\n",
      "0.3286553769356312\n",
      "episode: 147/2000, score: 250.0, rewards : -1426.0\n",
      "0.3264378836306879\n",
      "episode: 148/2000, score: 290.0, rewards : -1400.0\n",
      "0.3241899621285091\n",
      "episode: 149/2000, score: 340.0, rewards : -1516.0\n",
      "0.3214235114936456\n",
      "episode: 150/2000, score: 280.0, rewards : -1453.0\n",
      "0.31907288850600146\n",
      "episode: 151/2000, score: 330.0, rewards : -1369.0\n",
      "0.31684716627405496\n",
      "episode: 152/2000, score: 320.0, rewards : -1843.0\n",
      "0.31318042873789786\n",
      "episode: 153/2000, score: 320.0, rewards : -1441.0\n",
      "0.31080305129553687\n",
      "episode: 154/2000, score: 260.0, rewards : -1436.0\n",
      "0.3086442753080782\n",
      "episode: 155/2000, score: 180.0, rewards : -1489.0\n",
      "0.3065832604680915\n",
      "episode: 156/2000, score: 250.0, rewards : -1328.0\n",
      "0.30481326362566685\n",
      "episode: 157/2000, score: 510.0, rewards : -1358.0\n",
      "0.30217589912370735\n",
      "episode: 158/2000, score: 290.0, rewards : -1538.0\n",
      "0.29968120324808645\n",
      "episode: 159/2000, score: 270.0, rewards : -1969.0\n",
      "0.2959880825319349\n",
      "episode: 160/2000, score: 210.0, rewards : -1551.0\n",
      "0.29374121355147187\n",
      "episode: 161/2000, score: 340.0, rewards : -1322.0\n",
      "0.2918001413648795\n",
      "episode: 162/2000, score: 260.0, rewards : -1451.0\n",
      "0.28972989283773815\n",
      "episode: 163/2000, score: 210.0, rewards : -1495.0\n",
      "0.28769159326666827\n",
      "episode: 164/2000, score: 350.0, rewards : -1451.0\n",
      "0.28539352277874797\n",
      "episode: 165/2000, score: 260.0, rewards : -1483.0\n",
      "0.2832780636581283\n",
      "episode: 166/2000, score: 250.0, rewards : -1497.0\n",
      "0.2811670382645687\n",
      "episode: 167/2000, score: 290.0, rewards : -1501.0\n",
      "0.27894897933883966\n",
      "episode: 168/2000, score: 240.0, rewards : -1685.0\n",
      "0.2763778217665387\n",
      "episode: 169/2000, score: 240.0, rewards : -1416.0\n",
      "0.2745679623267162\n",
      "episode: 170/2000, score: 240.0, rewards : -1621.0\n",
      "0.2722113463156773\n",
      "episode: 171/2000, score: 240.0, rewards : -1442.0\n",
      "0.2703584683371642\n",
      "episode: 172/2000, score: 240.0, rewards : -1525.0\n",
      "0.2682954237029923\n",
      "episode: 173/2000, score: 310.0, rewards : -1522.0\n",
      "0.26606979431135513\n",
      "episode: 174/2000, score: 370.0, rewards : -1624.0\n",
      "0.26343551396470494\n",
      "episode: 175/2000, score: 180.0, rewards : -1546.0\n",
      "0.26152727309722923\n",
      "episode: 176/2000, score: 290.0, rewards : -1471.0\n",
      "0.25954199885091334\n",
      "episode: 177/2000, score: 290.0, rewards : -1493.0\n",
      "0.2575151351332763\n",
      "episode: 178/2000, score: 330.0, rewards : -1441.0\n",
      "0.2555347624623134\n",
      "episode: 179/2000, score: 210.0, rewards : -1450.0\n",
      "0.25385123943815846\n",
      "episode: 180/2000, score: 500.0, rewards : -1275.0\n",
      "0.2518889674709665\n",
      "episode: 181/2000, score: 230.0, rewards : -1548.0\n",
      "0.24993436569972716\n",
      "episode: 182/2000, score: 240.0, rewards : -1439.0\n",
      "0.2482405689796182\n",
      "episode: 183/2000, score: 240.0, rewards : -1480.0\n",
      "0.24645718239465178\n",
      "episode: 184/2000, score: 250.0, rewards : -1535.0\n",
      "0.24452761243715013\n",
      "episode: 185/2000, score: 300.0, rewards : -1374.0\n",
      "0.2428826009877072\n",
      "episode: 186/2000, score: 290.0, rewards : -1541.0\n",
      "0.2408701909200126\n",
      "episode: 187/2000, score: 290.0, rewards : -1440.0\n",
      "0.23911584101370537\n",
      "episode: 188/2000, score: 280.0, rewards : -1565.0\n",
      "0.23710144384128962\n",
      "episode: 189/2000, score: 300.0, rewards : -1455.0\n",
      "0.23531570658911338\n",
      "episode: 190/2000, score: 310.0, rewards : -1566.0\n",
      "0.23326100062394522\n",
      "episode: 191/2000, score: 290.0, rewards : -1517.0\n",
      "0.23138383630971912\n",
      "episode: 192/2000, score: 530.0, rewards : -1472.0\n",
      "0.22907464483974785\n",
      "episode: 193/2000, score: 290.0, rewards : -1437.0\n",
      "0.22741302873844946\n",
      "episode: 194/2000, score: 350.0, rewards : -1847.0\n",
      "0.224704861425377\n",
      "episode: 195/2000, score: 300.0, rewards : -1388.0\n",
      "0.22316195861956437\n",
      "episode: 196/2000, score: 320.0, rewards : -1487.0\n",
      "0.22136606619051355\n",
      "episode: 197/2000, score: 260.0, rewards : -1350.0\n",
      "0.22001763643184322\n",
      "episode: 198/2000, score: 270.0, rewards : -1440.0\n",
      "0.2184588512907403\n",
      "episode: 199/2000, score: 240.0, rewards : -1562.0\n",
      "0.21671164241098062\n",
      "episode: 200/2000, score: 290.0, rewards : -1610.0\n",
      "0.2147678308149821\n",
      "episode: 201/2000, score: 270.0, rewards : -1371.0\n",
      "0.21339343101318123\n",
      "episode: 202/2000, score: 240.0, rewards : -1803.0\n",
      "0.21117718146460634\n",
      "episode: 203/2000, score: 230.0, rewards : -1366.0\n",
      "0.2099202032197634\n",
      "episode: 204/2000, score: 360.0, rewards : -1537.0\n",
      "0.208043549199348\n",
      "episode: 205/2000, score: 240.0, rewards : -1660.0\n",
      "0.20617748672615852\n",
      "episode: 206/2000, score: 280.0, rewards : -1473.0\n",
      "0.20462874681937812\n",
      "episode: 207/2000, score: 300.0, rewards : -1378.0\n",
      "0.2032440171821049\n",
      "episode: 208/2000, score: 300.0, rewards : -1371.0\n",
      "0.20188278942834373\n",
      "episode: 209/2000, score: 320.0, rewards : -1455.0\n",
      "0.2003222339658977\n",
      "episode: 210/2000, score: 300.0, rewards : -1562.0\n",
      "0.19860088279376575\n",
      "episode: 211/2000, score: 200.0, rewards : -1446.0\n",
      "0.1973200765542332\n",
      "episode: 212/2000, score: 220.0, rewards : -1576.0\n",
      "0.1957536781015508\n",
      "episode: 213/2000, score: 190.0, rewards : -1407.0\n",
      "0.19458655843676936\n",
      "episode: 214/2000, score: 260.0, rewards : -1448.0\n",
      "0.1932118120983332\n",
      "episode: 215/2000, score: 300.0, rewards : -1376.0\n",
      "0.19190817938810995\n",
      "episode: 216/2000, score: 260.0, rewards : -1578.0\n",
      "0.1903047973393103\n",
      "episode: 217/2000, score: 290.0, rewards : -1501.0\n",
      "0.18880352870927164\n",
      "episode: 218/2000, score: 290.0, rewards : -1400.0\n",
      "0.18750338698811977\n",
      "episode: 219/2000, score: 270.0, rewards : -1359.0\n",
      "0.18632582298369388\n",
      "episode: 220/2000, score: 190.0, rewards : -1483.0\n",
      "0.18507420337495523\n",
      "episode: 221/2000, score: 270.0, rewards : -1544.0\n",
      "0.18357197101833683\n",
      "episode: 222/2000, score: 260.0, rewards : -1416.0\n",
      "0.1823333799430775\n",
      "episode: 223/2000, score: 230.0, rewards : -1684.0\n",
      "0.18067263072738943\n",
      "episode: 224/2000, score: 290.0, rewards : -1584.0\n",
      "0.17909863361835227\n",
      "episode: 225/2000, score: 240.0, rewards : -1737.0\n",
      "0.17735557770312657\n",
      "episode: 226/2000, score: 300.0, rewards : -1615.0\n",
      "0.1757384104589914\n",
      "episode: 227/2000, score: 310.0, rewards : -1349.0\n",
      "0.1745823503644853\n",
      "episode: 228/2000, score: 250.0, rewards : -1684.0\n",
      "0.17295760478706973\n",
      "episode: 229/2000, score: 300.0, rewards : -1522.0\n",
      "0.17153999806487719\n",
      "episode: 230/2000, score: 240.0, rewards : -1567.0\n",
      "0.17015953256928015\n",
      "episode: 231/2000, score: 230.0, rewards : -1451.0\n",
      "0.16900298707738118\n",
      "episode: 232/2000, score: 260.0, rewards : -1375.0\n",
      "0.16793153355616583\n",
      "episode: 233/2000, score: 220.0, rewards : -1480.0\n",
      "0.16675844412278054\n",
      "episode: 234/2000, score: 290.0, rewards : -1473.0\n",
      "0.16548925772928577\n",
      "episode: 235/2000, score: 300.0, rewards : -1346.0\n",
      "0.164421993219211\n",
      "episode: 236/2000, score: 250.0, rewards : -1486.0\n",
      "0.1632146516112417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 237/2000, score: 250.0, rewards : -1386.0\n",
      "0.1621782734674046\n",
      "episode: 238/2000, score: 180.0, rewards : -1520.0\n",
      "0.16104537355932577\n",
      "episode: 239/2000, score: 240.0, rewards : -1591.0\n",
      "0.1597110279545419\n",
      "episode: 240/2000, score: 300.0, rewards : -1375.0\n",
      "0.15863501704001162\n",
      "episode: 241/2000, score: 300.0, rewards : -1454.0\n",
      "0.15744182665702489\n",
      "episode: 242/2000, score: 350.0, rewards : -1611.0\n",
      "0.15593449065871606\n",
      "episode: 243/2000, score: 190.0, rewards : -1553.0\n",
      "0.15477863737490197\n",
      "episode: 244/2000, score: 260.0, rewards : -1415.0\n",
      "0.15373585714059765\n",
      "episode: 245/2000, score: 180.0, rewards : -1514.0\n",
      "0.1526710919545817\n",
      "episode: 246/2000, score: 270.0, rewards : -1539.0\n",
      "0.15143944485631403\n",
      "episode: 247/2000, score: 540.0, rewards : -1356.0\n",
      "0.15008710060579267\n",
      "episode: 248/2000, score: 220.0, rewards : -1696.0\n",
      "0.14871708615968068\n",
      "episode: 249/2000, score: 240.0, rewards : -1552.0\n",
      "0.14754241751005034\n",
      "episode: 250/2000, score: 210.0, rewards : -1400.0\n",
      "0.14664367729272393\n",
      "episode: 251/2000, score: 300.0, rewards : -1418.0\n",
      "0.14559308540384375\n",
      "episode: 252/2000, score: 240.0, rewards : -1542.0\n",
      "0.14445753733968147\n",
      "episode: 253/2000, score: 300.0, rewards : -1730.0\n",
      "0.1429758240780723\n",
      "episode: 254/2000, score: 220.0, rewards : -1488.0\n",
      "0.1419657055364051\n",
      "episode: 255/2000, score: 300.0, rewards : -1385.0\n",
      "0.1409951487595662\n",
      "episode: 256/2000, score: 300.0, rewards : -1347.0\n",
      "0.14008444949445592\n",
      "episode: 257/2000, score: 240.0, rewards : -1783.0\n",
      "0.13865729708688052\n",
      "episode: 258/2000, score: 300.0, rewards : -1524.0\n",
      "0.1375180744447487\n",
      "episode: 259/2000, score: 260.0, rewards : -1588.0\n",
      "0.1363554823664596\n",
      "episode: 260/2000, score: 280.0, rewards : -1368.0\n",
      "0.13547339634076375\n",
      "episode: 261/2000, score: 490.0, rewards : -1740.0\n",
      "0.13381593316086993\n",
      "episode: 262/2000, score: 300.0, rewards : -1712.0\n",
      "0.1324672138113418\n",
      "episode: 263/2000, score: 270.0, rewards : -1367.0\n",
      "0.1316247590632418\n",
      "episode: 264/2000, score: 290.0, rewards : -1332.0\n",
      "0.13080728181259116\n",
      "episode: 265/2000, score: 240.0, rewards : -1518.0\n",
      "0.1298182078820685\n",
      "episode: 266/2000, score: 270.0, rewards : -1377.0\n",
      "0.12897970139758141\n",
      "episode: 267/2000, score: 240.0, rewards : -1697.0\n",
      "0.12777552220708827\n",
      "episode: 268/2000, score: 230.0, rewards : -1570.0\n",
      "0.12675612332016897\n",
      "episode: 269/2000, score: 230.0, rewards : -1439.0\n",
      "0.12590969177381595\n",
      "episode: 270/2000, score: 230.0, rewards : -1369.0\n",
      "0.1251564917169503\n",
      "episode: 271/2000, score: 320.0, rewards : -1593.0\n",
      "0.12401776758572057\n",
      "episode: 272/2000, score: 240.0, rewards : -1496.0\n",
      "0.12310711197328023\n",
      "episode: 273/2000, score: 280.0, rewards : -1423.0\n",
      "0.12224347714833665\n",
      "episode: 274/2000, score: 290.0, rewards : -1689.0\n",
      "0.12105133614363069\n",
      "episode: 275/2000, score: 300.0, rewards : -1391.0\n",
      "0.12021654842035986\n",
      "episode: 276/2000, score: 270.0, rewards : -1339.0\n",
      "0.11948545591866656\n",
      "episode: 277/2000, score: 300.0, rewards : -1448.0\n",
      "0.11859384863336776\n",
      "episode: 278/2000, score: 240.0, rewards : -1533.0\n",
      "0.11767947087982578\n",
      "episode: 279/2000, score: 300.0, rewards : -1636.0\n",
      "0.11658195862490692\n",
      "episode: 280/2000, score: 300.0, rewards : -1526.0\n",
      "0.11562179676792014\n",
      "episode: 281/2000, score: 550.0, rewards : -1368.0\n",
      "0.1145640947520143\n",
      "episode: 282/2000, score: 240.0, rewards : -1638.0\n",
      "0.11356148427464308\n",
      "episode: 283/2000, score: 240.0, rewards : -1413.0\n",
      "0.11282121179569232\n",
      "episode: 284/2000, score: 290.0, rewards : -1674.0\n",
      "0.1117377179503612\n",
      "episode: 285/2000, score: 230.0, rewards : -1645.0\n",
      "0.11076316544043492\n",
      "episode: 286/2000, score: 240.0, rewards : -1487.0\n",
      "0.10995973361909411\n",
      "episode: 287/2000, score: 360.0, rewards : -1615.0\n",
      "0.10889174155815692\n",
      "episode: 288/2000, score: 300.0, rewards : -1568.0\n",
      "0.10794956728947183\n",
      "episode: 289/2000, score: 300.0, rewards : -1364.0\n",
      "0.10723408071913605\n",
      "episode: 290/2000, score: 240.0, rewards : -1409.0\n",
      "0.10653931615164139\n",
      "episode: 291/2000, score: 280.0, rewards : -1439.0\n",
      "0.10577498415081765\n",
      "episode: 292/2000, score: 260.0, rewards : -1542.0\n",
      "0.10492900793848836\n",
      "episode: 293/2000, score: 300.0, rewards : -1416.0\n",
      "0.10417935392452406\n",
      "episode: 294/2000, score: 300.0, rewards : -1533.0\n",
      "0.10331410688197305\n",
      "episode: 295/2000, score: 290.0, rewards : -1512.0\n",
      "0.10248781248427719\n",
      "episode: 296/2000, score: 280.0, rewards : -1385.0\n",
      "0.10180750817956191\n",
      "episode: 297/2000, score: 220.0, rewards : -1580.0\n",
      "0.10099528328135322\n",
      "episode: 298/2000, score: 300.0, rewards : -1635.0\n",
      "0.10005437305456819\n",
      "episode: 299/2000, score: 300.0, rewards : -1658.0\n",
      "0.09909943309805627\n",
      "episode: 300/2000, score: 300.0, rewards : -1439.0\n",
      "0.0983688003153943\n",
      "episode: 301/2000, score: 360.0, rewards : -1432.0\n",
      "0.09759181665590978\n",
      "episode: 302/2000, score: 300.0, rewards : -1571.0\n",
      "0.0967445113980631\n",
      "episode: 303/2000, score: 300.0, rewards : -1767.0\n",
      "0.09571677277079561\n",
      "episode: 304/2000, score: 240.0, rewards : -1399.0\n",
      "0.09510613848590767\n",
      "episode: 305/2000, score: 270.0, rewards : -1425.0\n",
      "0.09444649468710527\n",
      "episode: 306/2000, score: 290.0, rewards : -1324.0\n",
      "0.09386742830372731\n",
      "episode: 307/2000, score: 200.0, rewards : -1489.0\n",
      "0.09322196921585658\n",
      "episode: 308/2000, score: 300.0, rewards : -1334.0\n",
      "0.09263188226977623\n",
      "episode: 309/2000, score: 240.0, rewards : -1442.0\n",
      "0.09200135904916511\n",
      "episode: 310/2000, score: 240.0, rewards : -1690.0\n",
      "0.09114879696817571\n",
      "episode: 311/2000, score: 300.0, rewards : -1496.0\n",
      "0.09042522470412591\n",
      "episode: 312/2000, score: 910.0, rewards : -1072.0\n",
      "0.08954069490919331\n",
      "episode: 313/2000, score: 180.0, rewards : -1546.0\n",
      "0.08889209134486621\n",
      "episode: 314/2000, score: 240.0, rewards : -1649.0\n",
      "0.08810445796133952\n",
      "episode: 315/2000, score: 360.0, rewards : -1408.0\n",
      "0.08742952973008776\n",
      "episode: 316/2000, score: 290.0, rewards : -1478.0\n",
      "0.08675977181743118\n",
      "episode: 317/2000, score: 240.0, rewards : -1535.0\n",
      "0.08608911813658182\n",
      "episode: 318/2000, score: 260.0, rewards : -1466.0\n",
      "0.08546551666766543\n",
      "episode: 319/2000, score: 240.0, rewards : -1527.0\n",
      "0.08481165228345589\n",
      "episode: 320/2000, score: 240.0, rewards : -1492.0\n",
      "0.08419225264819738\n",
      "episode: 321/2000, score: 300.0, rewards : -1436.0\n",
      "0.08357403359063308\n",
      "episode: 322/2000, score: 210.0, rewards : -1521.0\n",
      "0.08296450222358455\n",
      "episode: 323/2000, score: 610.0, rewards : -1254.0\n",
      "0.08224995059776637\n",
      "episode: 324/2000, score: 300.0, rewards : -1578.0\n",
      "0.08153013814333984\n",
      "episode: 325/2000, score: 300.0, rewards : -1450.0\n",
      "0.0809201371765277\n",
      "episode: 326/2000, score: 300.0, rewards : -1670.0\n",
      "0.08013820117783295\n",
      "episode: 327/2000, score: 230.0, rewards : -1442.0\n",
      "0.07960067918663061\n",
      "episode: 328/2000, score: 240.0, rewards : -1568.0\n",
      "0.07895930434444827\n",
      "episode: 329/2000, score: 280.0, rewards : -1568.0\n",
      "0.07829177418807631\n",
      "episode: 330/2000, score: 300.0, rewards : -1361.0\n",
      "0.07777519183421296\n",
      "episode: 331/2000, score: 250.0, rewards : -1364.0\n",
      "0.07729833984302799\n",
      "episode: 332/2000, score: 230.0, rewards : -1461.0\n",
      "0.0767652791830977\n",
      "episode: 333/2000, score: 190.0, rewards : -1426.0\n",
      "0.07629309324121043\n",
      "episode: 334/2000, score: 240.0, rewards : -1752.0\n",
      "0.07553924809168688\n",
      "episode: 335/2000, score: 270.0, rewards : -1348.0\n",
      "0.0750731020257561\n",
      "episode: 336/2000, score: 220.0, rewards : -1494.0\n",
      "0.0745382410784802\n",
      "episode: 337/2000, score: 260.0, rewards : -1484.0\n",
      "0.07398499182855657\n",
      "episode: 338/2000, score: 220.0, rewards : -1533.0\n",
      "0.07342924002865271\n",
      "episode: 339/2000, score: 290.0, rewards : -1573.0\n",
      "0.07279754110534434\n",
      "episode: 340/2000, score: 190.0, rewards : -1542.0\n",
      "0.07226588337678536\n",
      "episode: 341/2000, score: 240.0, rewards : -1902.0\n",
      "0.07144458289710977\n",
      "episode: 342/2000, score: 240.0, rewards : -1437.0\n",
      "0.07096182461117338\n",
      "episode: 343/2000, score: 300.0, rewards : -1705.0\n",
      "0.070251523907056\n",
      "episode: 344/2000, score: 290.0, rewards : -1475.0\n",
      "0.06971545033654693\n",
      "episode: 345/2000, score: 210.0, rewards : -1387.0\n",
      "0.06929979391662176\n",
      "episode: 346/2000, score: 190.0, rewards : -1499.0\n",
      "0.06882326885804335\n",
      "episode: 347/2000, score: 240.0, rewards : -1854.0\n",
      "0.0680737613590719\n",
      "episode: 348/2000, score: 270.0, rewards : -1453.0\n",
      "0.06758268471399945\n",
      "episode: 349/2000, score: 240.0, rewards : -1422.0\n",
      "0.06713609137421053\n",
      "episode: 350/2000, score: 240.0, rewards : -1552.0\n",
      "0.06660580488304492\n",
      "episode: 351/2000, score: 280.0, rewards : -1420.0\n",
      "0.0661405285632506\n",
      "episode: 352/2000, score: 510.0, rewards : -1489.0\n",
      "0.06548241603398856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 353/2000, score: 240.0, rewards : -1576.0\n",
      "0.06494960154185997\n",
      "episode: 354/2000, score: 240.0, rewards : -1462.0\n",
      "0.06449460475560917\n",
      "episode: 355/2000, score: 290.0, rewards : -1511.0\n",
      "0.06397942408544767\n",
      "episode: 356/2000, score: 230.0, rewards : -1467.0\n",
      "0.06353440041962348\n",
      "episode: 357/2000, score: 250.0, rewards : -1513.0\n",
      "0.06305084471750799\n",
      "episode: 358/2000, score: 240.0, rewards : -1618.0\n",
      "0.06251155483110576\n",
      "episode: 359/2000, score: 300.0, rewards : -1437.0\n",
      "0.062051915413876904\n",
      "episode: 360/2000, score: 260.0, rewards : -1575.0\n",
      "0.06153532119062214\n",
      "episode: 361/2000, score: 240.0, rewards : -1447.0\n",
      "0.061113409113068694\n",
      "episode: 362/2000, score: 180.0, rewards : -1612.0\n",
      "0.06063069386083406\n",
      "episode: 363/2000, score: 300.0, rewards : -1416.0\n",
      "0.06019752438830011\n",
      "episode: 364/2000, score: 300.0, rewards : -1336.0\n",
      "0.059815282978149246\n",
      "episode: 365/2000, score: 240.0, rewards : -1352.0\n",
      "0.059461626210483086\n",
      "episode: 366/2000, score: 300.0, rewards : -1415.0\n",
      "0.05903739939005842\n",
      "episode: 367/2000, score: 240.0, rewards : -1444.0\n",
      "0.05863437312996772\n",
      "episode: 368/2000, score: 240.0, rewards : -1612.0\n",
      "0.05813634654018975\n",
      "episode: 369/2000, score: 240.0, rewards : -1495.0\n",
      "0.05771003166128252\n",
      "episode: 370/2000, score: 550.0, rewards : -1460.0\n",
      "0.05712951977085942\n",
      "episode: 371/2000, score: 260.0, rewards : -1417.0\n",
      "0.056743489816976675\n",
      "episode: 372/2000, score: 300.0, rewards : -1353.0\n",
      "0.05637359641394983\n",
      "episode: 373/2000, score: 240.0, rewards : -1440.0\n",
      "0.055990994547354005\n",
      "episode: 374/2000, score: 240.0, rewards : -1462.0\n",
      "0.055598756227591244\n",
      "episode: 375/2000, score: 190.0, rewards : -1522.0\n",
      "0.055203745009060806\n",
      "episode: 376/2000, score: 300.0, rewards : -1503.0\n",
      "0.05476168415481875\n",
      "episode: 377/2000, score: 240.0, rewards : -1424.0\n",
      "0.05439872531611699\n",
      "episode: 378/2000, score: 220.0, rewards : -1366.0\n",
      "0.05408033858585212\n",
      "episode: 379/2000, score: 300.0, rewards : -1560.0\n",
      "0.05361670336626892\n",
      "episode: 380/2000, score: 300.0, rewards : -1461.0\n",
      "0.05320969472390134\n",
      "episode: 381/2000, score: 240.0, rewards : -1596.0\n",
      "0.05276618603462869\n",
      "episode: 382/2000, score: 280.0, rewards : -1415.0\n",
      "0.052400206635629755\n",
      "episode: 383/2000, score: 290.0, rewards : -1485.0\n",
      "0.05199515264895709\n",
      "episode: 384/2000, score: 240.0, rewards : -1479.0\n",
      "0.051622130177133095\n",
      "episode: 385/2000, score: 260.0, rewards : -1426.0\n",
      "0.05126869979908567\n",
      "episode: 386/2000, score: 310.0, rewards : -1421.0\n",
      "0.05089478125844879\n",
      "episode: 387/2000, score: 300.0, rewards : -1370.0\n",
      "0.05055441876759602\n",
      "episode: 388/2000, score: 260.0, rewards : -1434.0\n",
      "0.050204281941326666\n",
      "episode: 389/2000, score: 300.0, rewards : -1528.0\n",
      "0.04978980674505611\n",
      "episode: 390/2000, score: 230.0, rewards : -1491.0\n",
      "0.049431617169768176\n",
      "episode: 391/2000, score: 300.0, rewards : -1359.0\n",
      "0.04910644113188533\n",
      "episode: 392/2000, score: 300.0, rewards : -1355.0\n",
      "0.04878535558468648\n",
      "episode: 393/2000, score: 300.0, rewards : -1498.0\n",
      "0.048397111751924585\n",
      "episode: 394/2000, score: 280.0, rewards : -1302.0\n",
      "0.04811577607409341\n",
      "episode: 395/2000, score: 240.0, rewards : -1550.0\n",
      "0.04773667969267195\n",
      "episode: 396/2000, score: 240.0, rewards : -1636.0\n",
      "0.04731985736515462\n",
      "episode: 397/2000, score: 250.0, rewards : -1509.0\n",
      "0.046961587806630456\n",
      "episode: 398/2000, score: 240.0, rewards : -1442.0\n",
      "0.04664193143278479\n",
      "episode: 399/2000, score: 170.0, rewards : -1478.0\n",
      "0.04634020395388701\n",
      "episode: 400/2000, score: 150.0, rewards : -1535.0\n",
      "0.04602339646282706\n",
      "episode: 401/2000, score: 220.0, rewards : -1445.0\n",
      "0.04571789755547085\n",
      "episode: 402/2000, score: 260.0, rewards : -1734.0\n",
      "0.04526525782861924\n",
      "episode: 403/2000, score: 290.0, rewards : -1527.0\n",
      "0.04489649646597969\n",
      "episode: 404/2000, score: 300.0, rewards : -1354.0\n",
      "0.04460338394002916\n",
      "episode: 405/2000, score: 240.0, rewards : -1532.0\n",
      "0.044259927235269864\n",
      "episode: 406/2000, score: 210.0, rewards : -1456.0\n",
      "0.04396569440677429\n",
      "episode: 407/2000, score: 240.0, rewards : -1457.0\n",
      "0.04365988086163701\n",
      "episode: 408/2000, score: 180.0, rewards : -1544.0\n",
      "0.04334448982243502\n",
      "episode: 409/2000, score: 220.0, rewards : -1555.0\n",
      "0.04300943659402025\n",
      "episode: 410/2000, score: 300.0, rewards : -1489.0\n",
      "0.04267099894162964\n",
      "episode: 411/2000, score: 210.0, rewards : -1444.0\n",
      "0.04239241586123069\n",
      "episode: 412/2000, score: 250.0, rewards : -1493.0\n",
      "0.04207818510397465\n",
      "episode: 413/2000, score: 270.0, rewards : -1467.0\n",
      "0.04176878962450706\n",
      "episode: 414/2000, score: 160.0, rewards : -1524.0\n",
      "0.04148364970905023\n",
      "episode: 415/2000, score: 240.0, rewards : -1441.0\n",
      "0.04120169237563441\n",
      "episode: 416/2000, score: 240.0, rewards : -1627.0\n",
      "0.0408456075492338\n",
      "episode: 417/2000, score: 240.0, rewards : -1594.0\n",
      "0.04050596500899071\n",
      "episode: 418/2000, score: 350.0, rewards : -1643.0\n",
      "0.040105328177376706\n",
      "episode: 419/2000, score: 240.0, rewards : -1604.0\n",
      "0.0397678642599962\n",
      "episode: 420/2000, score: 200.0, rewards : -1502.0\n",
      "0.03948927516930408\n",
      "episode: 421/2000, score: 290.0, rewards : -1483.0\n",
      "0.039184806471016534\n",
      "episode: 422/2000, score: 270.0, rewards : -1394.0\n",
      "0.03892509072138277\n",
      "episode: 423/2000, score: 240.0, rewards : -1468.0\n",
      "0.03865008649512789\n",
      "episode: 424/2000, score: 220.0, rewards : -1506.0\n",
      "0.038370117885461484\n",
      "episode: 425/2000, score: 240.0, rewards : -1357.0\n",
      "0.03814134813994047\n",
      "episode: 426/2000, score: 240.0, rewards : -1845.0\n",
      "0.03772937211809391\n",
      "episode: 427/2000, score: 240.0, rewards : -1378.0\n",
      "0.037496547476239664\n",
      "episode: 428/2000, score: 240.0, rewards : -1584.0\n",
      "0.037188471977984784\n",
      "episode: 429/2000, score: 240.0, rewards : -1500.0\n",
      "0.03691392248998672\n",
      "episode: 430/2000, score: 240.0, rewards : -1587.0\n",
      "0.0366095355906272\n",
      "episode: 431/2000, score: 260.0, rewards : -1502.0\n",
      "0.03633126638972799\n",
      "episode: 432/2000, score: 240.0, rewards : -1890.0\n",
      "0.035922672676825175\n",
      "episode: 433/2000, score: 230.0, rewards : -1450.0\n",
      "0.03567886915011108\n",
      "episode: 434/2000, score: 190.0, rewards : -1493.0\n",
      "0.03543565720216437\n",
      "episode: 435/2000, score: 240.0, rewards : -1543.0\n",
      "0.03515892646798\n",
      "episode: 436/2000, score: 250.0, rewards : -1441.0\n",
      "0.03491646536747613\n",
      "episode: 437/2000, score: 240.0, rewards : -1915.0\n",
      "0.03451515307539299\n",
      "episode: 438/2000, score: 240.0, rewards : -1520.0\n",
      "0.03425348834924884\n",
      "episode: 439/2000, score: 230.0, rewards : -1491.0\n",
      "0.034007067580701426\n",
      "episode: 440/2000, score: 230.0, rewards : -1468.0\n",
      "0.033770185860025975\n",
      "episode: 441/2000, score: 190.0, rewards : -1531.0\n",
      "0.03352724198614181\n",
      "episode: 442/2000, score: 290.0, rewards : -1442.0\n",
      "0.0332823845768317\n",
      "episode: 443/2000, score: 240.0, rewards : -1687.0\n",
      "0.0329749512079361\n",
      "episode: 444/2000, score: 240.0, rewards : -1788.0\n",
      "0.03263737706972965\n",
      "episode: 445/2000, score: 240.0, rewards : -1469.0\n",
      "0.03240647122375874\n",
      "episode: 446/2000, score: 230.0, rewards : -1419.0\n",
      "0.032196511220252334\n",
      "episode: 447/2000, score: 240.0, rewards : -1421.0\n",
      "0.031984073199466376\n",
      "episode: 448/2000, score: 220.0, rewards : -1445.0\n",
      "0.031771765978222406\n",
      "episode: 449/2000, score: 200.0, rewards : -1531.0\n",
      "0.03154004462748424\n",
      "episode: 450/2000, score: 240.0, rewards : -1536.0\n",
      "0.031295926885745215\n",
      "episode: 451/2000, score: 170.0, rewards : -1511.0\n",
      "0.031083213777005486\n",
      "episode: 452/2000, score: 180.0, rewards : -1534.0\n",
      "0.03086176033074394\n",
      "episode: 453/2000, score: 230.0, rewards : -1606.0\n",
      "0.030604524145797604\n",
      "episode: 454/2000, score: 190.0, rewards : -1567.0\n",
      "0.030373417697229232\n",
      "episode: 455/2000, score: 210.0, rewards : -1476.0\n",
      "0.03016546640846045\n",
      "episode: 456/2000, score: 210.0, rewards : -1447.0\n",
      "0.029967628251646887\n",
      "episode: 457/2000, score: 240.0, rewards : -1500.0\n",
      "0.029746387728565627\n",
      "episode: 458/2000, score: 210.0, rewards : -1461.0\n",
      "0.02954716115790614\n",
      "episode: 459/2000, score: 240.0, rewards : -1633.0\n",
      "0.029290042927188637\n",
      "episode: 460/2000, score: 220.0, rewards : -1570.0\n",
      "0.02905927143826421\n",
      "episode: 461/2000, score: 140.0, rewards : -1528.0\n",
      "0.02886551278889028\n",
      "episode: 462/2000, score: 300.0, rewards : -1489.0\n",
      "0.02863837248766906\n",
      "episode: 463/2000, score: 180.0, rewards : -1495.0\n",
      "0.02844542900865098\n",
      "episode: 464/2000, score: 170.0, rewards : -1500.0\n",
      "0.02825519816707222\n",
      "episode: 465/2000, score: 250.0, rewards : -1497.0\n",
      "0.028044636713564344\n",
      "episode: 466/2000, score: 230.0, rewards : -1629.0\n",
      "0.02780448576628123\n",
      "episode: 467/2000, score: 220.0, rewards : -1496.0\n",
      "0.027605839607602843\n",
      "episode: 468/2000, score: 240.0, rewards : -1752.0\n",
      "0.027333068804865548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 469/2000, score: 240.0, rewards : -1457.0\n",
      "0.027142947329850023\n",
      "episode: 470/2000, score: 180.0, rewards : -1475.0\n",
      "0.02696547146527684\n",
      "episode: 471/2000, score: 240.0, rewards : -1492.0\n",
      "0.026768536224181128\n",
      "episode: 472/2000, score: 230.0, rewards : -1537.0\n",
      "0.026563740265098862\n",
      "episode: 473/2000, score: 230.0, rewards : -1558.0\n",
      "0.026354975968739723\n",
      "episode: 474/2000, score: 190.0, rewards : -1535.0\n",
      "0.026164330769427813\n",
      "episode: 475/2000, score: 220.0, rewards : -1365.0\n",
      "0.026011455389081117\n",
      "episode: 476/2000, score: 160.0, rewards : -1622.0\n",
      "0.025808579972771518\n",
      "episode: 477/2000, score: 190.0, rewards : -1544.0\n",
      "0.025619581385637222\n",
      "episode: 478/2000, score: 220.0, rewards : -1536.0\n",
      "0.025426372407141448\n",
      "episode: 479/2000, score: 190.0, rewards : -1479.0\n",
      "0.025256584288421854\n",
      "episode: 480/2000, score: 240.0, rewards : -1382.0\n",
      "0.02509972411080883\n",
      "episode: 481/2000, score: 240.0, rewards : -1462.0\n",
      "0.024923890948863398\n",
      "episode: 482/2000, score: 240.0, rewards : -1609.0\n",
      "0.024712934655400517\n",
      "episode: 483/2000, score: 140.0, rewards : -1454.0\n",
      "0.024566328546863164\n",
      "episode: 484/2000, score: 300.0, rewards : -1491.0\n",
      "0.024372530708247072\n",
      "episode: 485/2000, score: 170.0, rewards : -1564.0\n",
      "0.02419404844096987\n",
      "episode: 486/2000, score: 240.0, rewards : -1554.0\n",
      "0.024002467341864585\n",
      "episode: 487/2000, score: 280.0, rewards : -1578.0\n",
      "0.023797168143350034\n",
      "episode: 488/2000, score: 240.0, rewards : -1450.0\n",
      "0.023633295723380184\n",
      "episode: 489/2000, score: 240.0, rewards : -1387.0\n",
      "0.023485342944452602\n",
      "episode: 490/2000, score: 240.0, rewards : -1630.0\n",
      "0.02328167285988232\n",
      "episode: 491/2000, score: 240.0, rewards : -1570.0\n",
      "0.023093621133198128\n",
      "episode: 492/2000, score: 240.0, rewards : -1416.0\n",
      "0.02294239261587198\n",
      "episode: 493/2000, score: 240.0, rewards : -1474.0\n",
      "0.022778938735371703\n",
      "episode: 494/2000, score: 140.0, rewards : -1510.0\n",
      "0.02263112874867972\n",
      "episode: 495/2000, score: 290.0, rewards : -1494.0\n",
      "0.022454168979027866\n",
      "episode: 496/2000, score: 240.0, rewards : -1681.0\n",
      "0.02224809198545742\n",
      "episode: 497/2000, score: 240.0, rewards : -1554.0\n",
      "0.022071919984894196\n",
      "episode: 498/2000, score: 300.0, rewards : -1500.0\n",
      "0.02189582921041627\n",
      "episode: 499/2000, score: 180.0, rewards : -1492.0\n",
      "0.02174896430025829\n",
      "episode: 500/2000, score: 220.0, rewards : -1391.0\n",
      "0.021616266444866784\n",
      "episode: 501/2000, score: 200.0, rewards : -1492.0\n",
      "0.021466982837132838\n",
      "episode: 502/2000, score: 240.0, rewards : -1386.0\n",
      "0.021332805270105983\n",
      "episode: 503/2000, score: 240.0, rewards : -1458.0\n",
      "0.02118420817018773\n",
      "episode: 504/2000, score: 240.0, rewards : -1479.0\n",
      "0.021032228893415023\n",
      "episode: 505/2000, score: 240.0, rewards : -1482.0\n",
      "0.020880713509067676\n",
      "episode: 506/2000, score: 110.0, rewards : -1574.0\n",
      "0.02073816868222017\n",
      "episode: 507/2000, score: 140.0, rewards : -1638.0\n",
      "0.020577245154502738\n",
      "episode: 508/2000, score: 170.0, rewards : -1711.0\n",
      "0.02039655098146202\n",
      "episode: 509/2000, score: 170.0, rewards : -1462.0\n",
      "0.020267847945094748\n",
      "episode: 510/2000, score: 230.0, rewards : -1429.0\n",
      "0.020134519948388458\n",
      "episode: 511/2000, score: 140.0, rewards : -1466.0\n",
      "0.02001267298272881\n",
      "episode: 512/2000, score: 130.0, rewards : -1521.0\n",
      "0.019882614157098036\n",
      "episode: 513/2000, score: 210.0, rewards : -1499.0\n",
      "0.0197419468530971\n",
      "episode: 514/2000, score: 160.0, rewards : -1444.0\n",
      "0.019622868055819927\n",
      "episode: 515/2000, score: 200.0, rewards : -1669.0\n",
      "0.01945288873602668\n",
      "episode: 516/2000, score: 240.0, rewards : -1709.0\n",
      "0.019268960416210294\n",
      "episode: 517/2000, score: 190.0, rewards : -1528.0\n",
      "0.019130912776556413\n",
      "episode: 518/2000, score: 240.0, rewards : -1507.0\n",
      "0.018988346698012432\n",
      "episode: 519/2000, score: 240.0, rewards : -1625.0\n",
      "0.018824616770798074\n",
      "episode: 520/2000, score: 240.0, rewards : -1629.0\n",
      "0.018661552149206295\n",
      "episode: 521/2000, score: 300.0, rewards : -1429.0\n",
      "0.018525818171639247\n",
      "episode: 522/2000, score: 160.0, rewards : -1546.0\n",
      "0.018395301903248475\n",
      "episode: 523/2000, score: 240.0, rewards : -1628.0\n",
      "0.01823613850049694\n",
      "episode: 524/2000, score: 230.0, rewards : -1491.0\n",
      "0.01810494709544027\n",
      "episode: 525/2000, score: 140.0, rewards : -1505.0\n",
      "0.01798836551821959\n",
      "episode: 526/2000, score: 240.0, rewards : -1466.0\n",
      "0.017861635658294645\n",
      "episode: 527/2000, score: 140.0, rewards : -1572.0\n",
      "0.01773473450177507\n",
      "episode: 528/2000, score: 240.0, rewards : -1586.0\n",
      "0.0175886723167403\n",
      "episode: 529/2000, score: 240.0, rewards : -1501.0\n",
      "0.017458646709588323\n",
      "episode: 530/2000, score: 170.0, rewards : -1459.0\n",
      "0.017349002429229318\n",
      "episode: 531/2000, score: 170.0, rewards : -1509.0\n",
      "0.017231428828138037\n",
      "episode: 532/2000, score: 140.0, rewards : -1509.0\n",
      "0.01711978721087599\n",
      "episode: 533/2000, score: 240.0, rewards : -1590.0\n",
      "0.01697811055259122\n",
      "episode: 534/2000, score: 180.0, rewards : -1678.0\n",
      "0.01683289246150533\n",
      "episode: 535/2000, score: 240.0, rewards : -1381.0\n",
      "0.01672851629490539\n",
      "episode: 536/2000, score: 240.0, rewards : -1827.0\n",
      "0.016550805517056618\n",
      "episode: 537/2000, score: 140.0, rewards : -1447.0\n",
      "0.016453771853991658\n",
      "episode: 538/2000, score: 220.0, rewards : -1386.0\n",
      "0.016354199468893608\n",
      "episode: 539/2000, score: 190.0, rewards : -1433.0\n",
      "0.01625246649253327\n",
      "episode: 540/2000, score: 140.0, rewards : -1633.0\n",
      "0.01612715734731023\n",
      "episode: 541/2000, score: 240.0, rewards : -1671.0\n",
      "0.015980745592657494\n",
      "episode: 542/2000, score: 210.0, rewards : -1964.0\n",
      "0.01579406976679101\n",
      "episode: 543/2000, score: 190.0, rewards : -1549.0\n",
      "0.015677624447352583\n",
      "episode: 544/2000, score: 240.0, rewards : -1527.0\n",
      "0.015557680864784696\n",
      "episode: 545/2000, score: 210.0, rewards : -1473.0\n",
      "0.015451628908576735\n",
      "episode: 546/2000, score: 170.0, rewards : -1591.0\n",
      "0.015334334369569219\n",
      "episode: 547/2000, score: 240.0, rewards : -1591.0\n",
      "0.015207281345839933\n",
      "episode: 548/2000, score: 130.0, rewards : -1479.0\n",
      "0.015114798825677988\n",
      "episode: 549/2000, score: 110.0, rewards : -1585.0\n",
      "0.015009964548162051\n",
      "episode: 550/2000, score: 230.0, rewards : -1496.0\n",
      "0.01490123726481638\n",
      "episode: 551/2000, score: 200.0, rewards : -1465.0\n",
      "0.014802324275933986\n",
      "episode: 552/2000, score: 140.0, rewards : -1773.0\n",
      "0.014667646772433712\n",
      "episode: 553/2000, score: 170.0, rewards : -1440.0\n",
      "0.014578300235550342\n",
      "episode: 554/2000, score: 240.0, rewards : -1383.0\n",
      "0.014487614422645963\n",
      "episode: 555/2000, score: 110.0, rewards : -1573.0\n",
      "0.014388856782374126\n",
      "episode: 556/2000, score: 240.0, rewards : -1412.0\n",
      "0.014295203191083374\n",
      "episode: 557/2000, score: 170.0, rewards : -1494.0\n",
      "0.014200455003015014\n",
      "episode: 558/2000, score: 240.0, rewards : -1610.0\n",
      "0.014080121275498646\n",
      "episode: 559/2000, score: 220.0, rewards : -1589.0\n",
      "0.013966532381293436\n",
      "episode: 560/2000, score: 220.0, rewards : -1489.0\n",
      "0.013867720703875411\n",
      "episode: 561/2000, score: 140.0, rewards : -1449.0\n",
      "0.013786141638717449\n",
      "episode: 562/2000, score: 240.0, rewards : -1399.0\n",
      "0.013698191632702519\n",
      "episode: 563/2000, score: 140.0, rewards : -1461.0\n",
      "0.01361597582586844\n",
      "episode: 564/2000, score: 140.0, rewards : -1569.0\n",
      "0.013519644297447063\n",
      "episode: 565/2000, score: 300.0, rewards : -1342.0\n",
      "0.013432991438846036\n",
      "episode: 566/2000, score: 240.0, rewards : -1476.0\n",
      "0.013337020875990957\n",
      "episode: 567/2000, score: 170.0, rewards : -1514.0\n",
      "0.013245974019253806\n",
      "episode: 568/2000, score: 160.0, rewards : -1557.0\n",
      "0.013151208068846803\n",
      "episode: 569/2000, score: 170.0, rewards : -1646.0\n",
      "0.013044199887529195\n",
      "episode: 570/2000, score: 170.0, rewards : -1718.0\n",
      "0.01292875030702078\n",
      "episode: 571/2000, score: 140.0, rewards : -1578.0\n",
      "0.012836125514348672\n",
      "episode: 572/2000, score: 120.0, rewards : -1571.0\n",
      "0.012747605714938695\n",
      "episode: 573/2000, score: 240.0, rewards : -1525.0\n",
      "0.012650331604271866\n",
      "episode: 574/2000, score: 200.0, rewards : -1699.0\n",
      "0.01253698886053241\n",
      "episode: 575/2000, score: 230.0, rewards : -1501.0\n",
      "0.012445552709487408\n",
      "episode: 576/2000, score: 240.0, rewards : -1664.0\n",
      "0.012333428026311167\n",
      "episode: 577/2000, score: 240.0, rewards : -1777.0\n",
      "0.012208510015885505\n",
      "episode: 578/2000, score: 140.0, rewards : -1555.0\n",
      "0.012123833379310799\n",
      "episode: 579/2000, score: 70.0, rewards : -1633.0\n",
      "0.012038780903053728\n",
      "episode: 580/2000, score: 240.0, rewards : -1508.0\n",
      "0.01194894683348643\n",
      "episode: 581/2000, score: 70.0, rewards : -1623.0\n",
      "0.01186630781833332\n",
      "episode: 582/2000, score: 160.0, rewards : -1441.0\n",
      "0.01179508687927911\n",
      "episode: 583/2000, score: 240.0, rewards : -1434.0\n",
      "0.011715737750687029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 584/2000, score: 240.0, rewards : -1604.0\n",
      "0.011617156366715701\n",
      "episode: 585/2000, score: 170.0, rewards : -1557.0\n",
      "0.011532890148235957\n",
      "episode: 586/2000, score: 220.0, rewards : -1410.0\n",
      "0.011460346365019379\n",
      "episode: 587/2000, score: 170.0, rewards : -1620.0\n",
      "0.01137005215818534\n",
      "episode: 588/2000, score: 140.0, rewards : -1622.0\n",
      "0.011283628354190136\n",
      "episode: 589/2000, score: 230.0, rewards : -1456.0\n",
      "0.011206375109868646\n",
      "episode: 590/2000, score: 230.0, rewards : -1434.0\n",
      "0.011132099583856078\n",
      "episode: 591/2000, score: 240.0, rewards : -1533.0\n",
      "0.011046269295632925\n",
      "episode: 592/2000, score: 170.0, rewards : -1615.0\n",
      "0.010959785513061746\n",
      "episode: 593/2000, score: 240.0, rewards : -1519.0\n",
      "0.010876806448121123\n",
      "episode: 594/2000, score: 140.0, rewards : -1592.0\n",
      "0.010797370547919242\n",
      "episode: 595/2000, score: 70.0, rewards : -1628.0\n",
      "0.010722159719814424\n",
      "episode: 596/2000, score: 140.0, rewards : -1591.0\n",
      "0.010643959680987258\n",
      "episode: 597/2000, score: 170.0, rewards : -1603.0\n",
      "0.010561893030363735\n",
      "episode: 598/2000, score: 200.0, rewards : -1452.0\n",
      "0.0104931482212324\n",
      "episode: 599/2000, score: 200.0, rewards : -1497.0\n",
      "0.010420160704476806\n",
      "episode: 600/2000, score: 140.0, rewards : -1612.0\n",
      "0.010341991181137896\n",
      "episode: 601/2000, score: 240.0, rewards : -1398.0\n",
      "0.010276116222759464\n",
      "episode: 602/2000, score: 240.0, rewards : -1505.0\n",
      "0.010199741246723704\n",
      "episode: 603/2000, score: 240.0, rewards : -1452.0\n",
      "0.010129301044890135\n",
      "episode: 604/2000, score: 240.0, rewards : -1567.0\n",
      "0.010047785650552228\n",
      "episode: 605/2000, score: 190.0, rewards : -1443.0\n",
      "0.009999971601096055\n",
      "episode: 606/2000, score: 240.0, rewards : -1579.0\n",
      "0.009999971601096055\n",
      "episode: 607/2000, score: 210.0, rewards : -1431.0\n",
      "0.009999971601096055\n",
      "episode: 608/2000, score: 140.0, rewards : -1444.0\n",
      "0.009999971601096055\n",
      "episode: 609/2000, score: 240.0, rewards : -1575.0\n",
      "0.009999971601096055\n",
      "episode: 610/2000, score: 240.0, rewards : -1762.0\n",
      "0.009999971601096055\n",
      "episode: 611/2000, score: 140.0, rewards : -1449.0\n",
      "0.009999971601096055\n",
      "episode: 612/2000, score: 170.0, rewards : -1693.0\n",
      "0.009999971601096055\n",
      "episode: 613/2000, score: 130.0, rewards : -1468.0\n",
      "0.009999971601096055\n",
      "episode: 614/2000, score: 100.0, rewards : -1572.0\n",
      "0.009999971601096055\n",
      "episode: 615/2000, score: 240.0, rewards : -1364.0\n",
      "0.009999971601096055\n",
      "episode: 616/2000, score: 190.0, rewards : -1688.0\n",
      "0.009999971601096055\n",
      "episode: 617/2000, score: 240.0, rewards : -1424.0\n",
      "0.009999971601096055\n",
      "episode: 618/2000, score: 180.0, rewards : -1427.0\n",
      "0.009999971601096055\n",
      "episode: 619/2000, score: 140.0, rewards : -1459.0\n",
      "0.009999971601096055\n",
      "episode: 620/2000, score: 240.0, rewards : -1628.0\n",
      "0.009999971601096055\n",
      "episode: 621/2000, score: 140.0, rewards : -1502.0\n",
      "0.009999971601096055\n",
      "episode: 622/2000, score: 240.0, rewards : -1598.0\n",
      "0.009999971601096055\n",
      "episode: 623/2000, score: 140.0, rewards : -1473.0\n",
      "0.009999971601096055\n",
      "episode: 624/2000, score: 70.0, rewards : -1619.0\n",
      "0.009999971601096055\n",
      "episode: 625/2000, score: 140.0, rewards : -1462.0\n",
      "0.009999971601096055\n",
      "episode: 626/2000, score: 160.0, rewards : -1724.0\n",
      "0.009999971601096055\n",
      "episode: 627/2000, score: 230.0, rewards : -1634.0\n",
      "0.009999971601096055\n",
      "episode: 628/2000, score: 240.0, rewards : -1517.0\n",
      "0.009999971601096055\n",
      "episode: 629/2000, score: 140.0, rewards : -1443.0\n",
      "0.009999971601096055\n",
      "episode: 630/2000, score: 230.0, rewards : -1466.0\n",
      "0.009999971601096055\n",
      "episode: 631/2000, score: 130.0, rewards : -1701.0\n",
      "0.009999971601096055\n",
      "episode: 632/2000, score: 70.0, rewards : -1620.0\n",
      "0.009999971601096055\n",
      "episode: 633/2000, score: 170.0, rewards : -1978.0\n",
      "0.009999971601096055\n",
      "episode: 634/2000, score: 140.0, rewards : -1568.0\n",
      "0.009999971601096055\n",
      "episode: 635/2000, score: 240.0, rewards : -1487.0\n",
      "0.009999971601096055\n",
      "episode: 636/2000, score: 140.0, rewards : -1580.0\n",
      "0.009999971601096055\n",
      "episode: 637/2000, score: 170.0, rewards : -1592.0\n",
      "0.009999971601096055\n",
      "episode: 638/2000, score: 140.0, rewards : -1469.0\n",
      "0.009999971601096055\n",
      "episode: 639/2000, score: 240.0, rewards : -1495.0\n",
      "0.009999971601096055\n",
      "episode: 640/2000, score: 140.0, rewards : -1591.0\n",
      "0.009999971601096055\n",
      "episode: 641/2000, score: 140.0, rewards : -1471.0\n",
      "0.009999971601096055\n",
      "episode: 642/2000, score: 140.0, rewards : -1471.0\n",
      "0.009999971601096055\n",
      "episode: 643/2000, score: 240.0, rewards : -1843.0\n",
      "0.009999971601096055\n",
      "episode: 644/2000, score: 140.0, rewards : -1806.0\n",
      "0.009999971601096055\n",
      "episode: 645/2000, score: 140.0, rewards : -1571.0\n",
      "0.009999971601096055\n",
      "episode: 646/2000, score: 170.0, rewards : -1593.0\n",
      "0.009999971601096055\n",
      "episode: 647/2000, score: 140.0, rewards : -1508.0\n",
      "0.009999971601096055\n",
      "episode: 648/2000, score: 170.0, rewards : -1710.0\n",
      "0.009999971601096055\n",
      "episode: 649/2000, score: 300.0, rewards : -1471.0\n",
      "0.009999971601096055\n",
      "episode: 650/2000, score: 180.0, rewards : -1555.0\n",
      "0.009999971601096055\n",
      "episode: 651/2000, score: 230.0, rewards : -1433.0\n",
      "0.009999971601096055\n",
      "episode: 652/2000, score: 240.0, rewards : -1701.0\n",
      "0.009999971601096055\n",
      "episode: 653/2000, score: 230.0, rewards : -1390.0\n",
      "0.009999971601096055\n",
      "episode: 654/2000, score: 170.0, rewards : -1750.0\n",
      "0.009999971601096055\n",
      "episode: 655/2000, score: 240.0, rewards : -1636.0\n",
      "0.009999971601096055\n",
      "episode: 656/2000, score: 240.0, rewards : -1417.0\n",
      "0.009999971601096055\n",
      "episode: 657/2000, score: 70.0, rewards : -1610.0\n",
      "0.009999971601096055\n",
      "episode: 658/2000, score: 240.0, rewards : -1515.0\n",
      "0.009999971601096055\n",
      "episode: 659/2000, score: 240.0, rewards : -1749.0\n",
      "0.009999971601096055\n",
      "episode: 660/2000, score: 240.0, rewards : -1845.0\n",
      "0.009999971601096055\n",
      "episode: 661/2000, score: 140.0, rewards : -1455.0\n",
      "0.009999971601096055\n",
      "episode: 662/2000, score: 140.0, rewards : -1475.0\n",
      "0.009999971601096055\n",
      "episode: 663/2000, score: 240.0, rewards : -1434.0\n",
      "0.009999971601096055\n",
      "episode: 664/2000, score: 190.0, rewards : -1549.0\n",
      "0.009999971601096055\n",
      "episode: 665/2000, score: 140.0, rewards : -1537.0\n",
      "0.009999971601096055\n",
      "episode: 666/2000, score: 490.0, rewards : -1475.0\n",
      "0.009999971601096055\n",
      "episode: 667/2000, score: 230.0, rewards : -1453.0\n",
      "0.009999971601096055\n",
      "episode: 668/2000, score: 70.0, rewards : -1616.0\n",
      "0.009999971601096055\n",
      "episode: 669/2000, score: 220.0, rewards : -1474.0\n",
      "0.009999971601096055\n",
      "episode: 670/2000, score: 240.0, rewards : -1491.0\n",
      "0.009999971601096055\n",
      "episode: 671/2000, score: 210.0, rewards : -1723.0\n",
      "0.009999971601096055\n",
      "episode: 672/2000, score: 140.0, rewards : -1449.0\n",
      "0.009999971601096055\n",
      "episode: 673/2000, score: 140.0, rewards : -1467.0\n",
      "0.009999971601096055\n",
      "episode: 674/2000, score: 140.0, rewards : -1505.0\n",
      "0.009999971601096055\n",
      "episode: 675/2000, score: 150.0, rewards : -1534.0\n",
      "0.009999971601096055\n",
      "episode: 676/2000, score: 240.0, rewards : -2017.0\n",
      "0.009999971601096055\n",
      "episode: 677/2000, score: 230.0, rewards : -1460.0\n",
      "0.009999971601096055\n",
      "episode: 678/2000, score: 230.0, rewards : -1428.0\n",
      "0.009999971601096055\n",
      "episode: 679/2000, score: 220.0, rewards : -1508.0\n",
      "0.009999971601096055\n",
      "episode: 680/2000, score: 230.0, rewards : -1508.0\n",
      "0.009999971601096055\n",
      "episode: 681/2000, score: 180.0, rewards : -1524.0\n",
      "0.009999971601096055\n",
      "episode: 682/2000, score: 140.0, rewards : -1459.0\n",
      "0.009999971601096055\n",
      "episode: 683/2000, score: 140.0, rewards : -1601.0\n",
      "0.009999971601096055\n",
      "episode: 684/2000, score: 70.0, rewards : -1627.0\n",
      "0.009999971601096055\n",
      "episode: 685/2000, score: 240.0, rewards : -1489.0\n",
      "0.009999971601096055\n",
      "episode: 686/2000, score: 150.0, rewards : -1450.0\n",
      "0.009999971601096055\n",
      "episode: 687/2000, score: 100.0, rewards : -1529.0\n",
      "0.009999971601096055\n",
      "episode: 688/2000, score: 170.0, rewards : -1610.0\n",
      "0.009999971601096055\n",
      "episode: 689/2000, score: 170.0, rewards : -1551.0\n",
      "0.009999971601096055\n",
      "episode: 690/2000, score: 240.0, rewards : -1523.0\n",
      "0.009999971601096055\n",
      "episode: 691/2000, score: 140.0, rewards : -1568.0\n",
      "0.009999971601096055\n",
      "episode: 692/2000, score: 140.0, rewards : -1522.0\n",
      "0.009999971601096055\n",
      "episode: 693/2000, score: 190.0, rewards : -1532.0\n",
      "0.009999971601096055\n",
      "episode: 694/2000, score: 140.0, rewards : -1556.0\n",
      "0.009999971601096055\n",
      "episode: 695/2000, score: 240.0, rewards : -2143.0\n",
      "0.009999971601096055\n",
      "episode: 696/2000, score: 390.0, rewards : -1613.0\n",
      "0.009999971601096055\n",
      "episode: 697/2000, score: 140.0, rewards : -1470.0\n",
      "0.009999971601096055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 698/2000, score: 140.0, rewards : -1571.0\n",
      "0.009999971601096055\n",
      "episode: 699/2000, score: 240.0, rewards : -1656.0\n",
      "0.009999971601096055\n",
      "episode: 700/2000, score: 140.0, rewards : -1591.0\n",
      "0.009999971601096055\n",
      "episode: 701/2000, score: 140.0, rewards : -1470.0\n",
      "0.009999971601096055\n",
      "episode: 702/2000, score: 170.0, rewards : -1450.0\n",
      "0.009999971601096055\n",
      "episode: 703/2000, score: 240.0, rewards : -1622.0\n",
      "0.009999971601096055\n",
      "episode: 704/2000, score: 170.0, rewards : -1624.0\n",
      "0.009999971601096055\n",
      "episode: 705/2000, score: 240.0, rewards : -1481.0\n",
      "0.009999971601096055\n",
      "episode: 706/2000, score: 240.0, rewards : -1601.0\n",
      "0.009999971601096055\n",
      "episode: 707/2000, score: 100.0, rewards : -1577.0\n",
      "0.009999971601096055\n",
      "episode: 708/2000, score: 170.0, rewards : -1499.0\n",
      "0.009999971601096055\n",
      "episode: 709/2000, score: 120.0, rewards : -1565.0\n",
      "0.009999971601096055\n",
      "episode: 710/2000, score: 240.0, rewards : -1607.0\n",
      "0.009999971601096055\n",
      "episode: 711/2000, score: 150.0, rewards : -1504.0\n",
      "0.009999971601096055\n",
      "episode: 712/2000, score: 240.0, rewards : -1440.0\n",
      "0.009999971601096055\n",
      "episode: 713/2000, score: 70.0, rewards : -1624.0\n",
      "0.009999971601096055\n",
      "episode: 714/2000, score: 230.0, rewards : -1483.0\n",
      "0.009999971601096055\n",
      "episode: 715/2000, score: 230.0, rewards : -1432.0\n",
      "0.009999971601096055\n",
      "episode: 716/2000, score: 200.0, rewards : -1493.0\n",
      "0.009999971601096055\n",
      "episode: 717/2000, score: 300.0, rewards : -1408.0\n",
      "0.009999971601096055\n",
      "episode: 718/2000, score: 170.0, rewards : -1719.0\n",
      "0.009999971601096055\n",
      "episode: 719/2000, score: 240.0, rewards : -1460.0\n",
      "0.009999971601096055\n",
      "episode: 720/2000, score: 300.0, rewards : -1436.0\n",
      "0.009999971601096055\n",
      "episode: 721/2000, score: 140.0, rewards : -1565.0\n",
      "0.009999971601096055\n",
      "episode: 722/2000, score: 260.0, rewards : -1528.0\n",
      "0.009999971601096055\n",
      "episode: 723/2000, score: 140.0, rewards : -1505.0\n",
      "0.009999971601096055\n",
      "episode: 724/2000, score: 170.0, rewards : -1479.0\n",
      "0.009999971601096055\n",
      "episode: 725/2000, score: 240.0, rewards : -1448.0\n",
      "0.009999971601096055\n",
      "episode: 726/2000, score: 140.0, rewards : -1628.0\n",
      "0.009999971601096055\n",
      "episode: 727/2000, score: 140.0, rewards : -1471.0\n",
      "0.009999971601096055\n",
      "episode: 728/2000, score: 200.0, rewards : -1419.0\n",
      "0.009999971601096055\n",
      "episode: 729/2000, score: 240.0, rewards : -1639.0\n",
      "0.009999971601096055\n",
      "episode: 730/2000, score: 240.0, rewards : -1690.0\n",
      "0.009999971601096055\n",
      "episode: 731/2000, score: 190.0, rewards : -1570.0\n",
      "0.009999971601096055\n",
      "episode: 732/2000, score: 170.0, rewards : -1596.0\n",
      "0.009999971601096055\n",
      "episode: 733/2000, score: 120.0, rewards : -1543.0\n",
      "0.009999971601096055\n",
      "episode: 734/2000, score: 170.0, rewards : -1712.0\n",
      "0.009999971601096055\n",
      "episode: 735/2000, score: 140.0, rewards : -1468.0\n",
      "0.009999971601096055\n",
      "episode: 736/2000, score: 170.0, rewards : -1733.0\n",
      "0.009999971601096055\n",
      "episode: 737/2000, score: 70.0, rewards : -1621.0\n",
      "0.009999971601096055\n",
      "episode: 738/2000, score: 70.0, rewards : -1622.0\n",
      "0.009999971601096055\n",
      "episode: 739/2000, score: 240.0, rewards : -1441.0\n",
      "0.009999971601096055\n",
      "episode: 740/2000, score: 130.0, rewards : -1519.0\n",
      "0.009999971601096055\n",
      "episode: 741/2000, score: 90.0, rewards : -1600.0\n",
      "0.009999971601096055\n",
      "episode: 742/2000, score: 140.0, rewards : -1498.0\n",
      "0.009999971601096055\n",
      "episode: 743/2000, score: 170.0, rewards : -1723.0\n",
      "0.009999971601096055\n",
      "episode: 744/2000, score: 120.0, rewards : -1542.0\n",
      "0.009999971601096055\n",
      "episode: 745/2000, score: 170.0, rewards : -1698.0\n",
      "0.009999971601096055\n",
      "episode: 746/2000, score: 170.0, rewards : -1714.0\n",
      "0.009999971601096055\n",
      "episode: 747/2000, score: 70.0, rewards : -1609.0\n",
      "0.009999971601096055\n",
      "episode: 748/2000, score: 240.0, rewards : -1603.0\n",
      "0.009999971601096055\n",
      "episode: 749/2000, score: 300.0, rewards : -1542.0\n",
      "0.009999971601096055\n",
      "episode: 750/2000, score: 240.0, rewards : -1458.0\n",
      "0.009999971601096055\n",
      "episode: 751/2000, score: 140.0, rewards : -1464.0\n",
      "0.009999971601096055\n",
      "episode: 752/2000, score: 140.0, rewards : -1558.0\n",
      "0.009999971601096055\n",
      "episode: 753/2000, score: 220.0, rewards : -1445.0\n",
      "0.009999971601096055\n",
      "episode: 754/2000, score: 190.0, rewards : -1564.0\n",
      "0.009999971601096055\n",
      "episode: 755/2000, score: 240.0, rewards : -1578.0\n",
      "0.009999971601096055\n",
      "episode: 756/2000, score: 230.0, rewards : -1615.0\n",
      "0.009999971601096055\n",
      "episode: 757/2000, score: 240.0, rewards : -1401.0\n",
      "0.009999971601096055\n",
      "episode: 758/2000, score: 140.0, rewards : -1470.0\n",
      "0.009999971601096055\n",
      "episode: 759/2000, score: 70.0, rewards : -1637.0\n",
      "0.009999971601096055\n",
      "episode: 760/2000, score: 240.0, rewards : -1627.0\n",
      "0.009999971601096055\n",
      "episode: 761/2000, score: 170.0, rewards : -1612.0\n",
      "0.009999971601096055\n",
      "episode: 762/2000, score: 230.0, rewards : -1604.0\n",
      "0.009999971601096055\n",
      "episode: 763/2000, score: 220.0, rewards : -1580.0\n",
      "0.009999971601096055\n",
      "episode: 764/2000, score: 140.0, rewards : -1506.0\n",
      "0.009999971601096055\n",
      "episode: 765/2000, score: 140.0, rewards : -1598.0\n",
      "0.009999971601096055\n",
      "episode: 766/2000, score: 140.0, rewards : -1514.0\n",
      "0.009999971601096055\n",
      "episode: 767/2000, score: 210.0, rewards : -1400.0\n",
      "0.009999971601096055\n",
      "episode: 768/2000, score: 170.0, rewards : -1479.0\n",
      "0.009999971601096055\n",
      "episode: 769/2000, score: 240.0, rewards : -1580.0\n",
      "0.009999971601096055\n",
      "episode: 770/2000, score: 240.0, rewards : -1668.0\n",
      "0.009999971601096055\n",
      "episode: 771/2000, score: 70.0, rewards : -1622.0\n",
      "0.009999971601096055\n",
      "episode: 772/2000, score: 200.0, rewards : -1387.0\n",
      "0.009999971601096055\n",
      "episode: 773/2000, score: 170.0, rewards : -1607.0\n",
      "0.009999971601096055\n",
      "episode: 774/2000, score: 190.0, rewards : -1478.0\n",
      "0.009999971601096055\n",
      "episode: 775/2000, score: 190.0, rewards : -1475.0\n",
      "0.009999971601096055\n",
      "episode: 776/2000, score: 80.0, rewards : -1603.0\n",
      "0.009999971601096055\n",
      "episode: 777/2000, score: 130.0, rewards : -1529.0\n",
      "0.009999971601096055\n",
      "episode: 778/2000, score: 240.0, rewards : -1442.0\n",
      "0.009999971601096055\n",
      "episode: 779/2000, score: 240.0, rewards : -1448.0\n",
      "0.009999971601096055\n",
      "episode: 780/2000, score: 70.0, rewards : -1616.0\n",
      "0.009999971601096055\n",
      "episode: 781/2000, score: 240.0, rewards : -1475.0\n",
      "0.009999971601096055\n",
      "episode: 782/2000, score: 220.0, rewards : -1701.0\n",
      "0.009999971601096055\n",
      "episode: 783/2000, score: 70.0, rewards : -1634.0\n",
      "0.009999971601096055\n",
      "episode: 784/2000, score: 280.0, rewards : -1498.0\n",
      "0.009999971601096055\n",
      "episode: 785/2000, score: 200.0, rewards : -1755.0\n",
      "0.009999971601096055\n",
      "episode: 786/2000, score: 140.0, rewards : -1460.0\n",
      "0.009999971601096055\n",
      "episode: 787/2000, score: 140.0, rewards : -1462.0\n",
      "0.009999971601096055\n",
      "episode: 788/2000, score: 160.0, rewards : -1643.0\n",
      "0.009999971601096055\n",
      "episode: 789/2000, score: 240.0, rewards : -1608.0\n",
      "0.009999971601096055\n",
      "episode: 790/2000, score: 230.0, rewards : -1585.0\n",
      "0.009999971601096055\n",
      "episode: 791/2000, score: 240.0, rewards : -1589.0\n",
      "0.009999971601096055\n",
      "episode: 792/2000, score: 290.0, rewards : -1829.0\n",
      "0.009999971601096055\n",
      "episode: 793/2000, score: 140.0, rewards : -1503.0\n",
      "0.009999971601096055\n",
      "episode: 794/2000, score: 240.0, rewards : -1554.0\n",
      "0.009999971601096055\n",
      "episode: 795/2000, score: 140.0, rewards : -1461.0\n",
      "0.009999971601096055\n",
      "episode: 796/2000, score: 240.0, rewards : -1693.0\n",
      "0.009999971601096055\n",
      "episode: 797/2000, score: 240.0, rewards : -1366.0\n",
      "0.009999971601096055\n",
      "episode: 798/2000, score: 120.0, rewards : -1573.0\n",
      "0.009999971601096055\n",
      "episode: 799/2000, score: 220.0, rewards : -1647.0\n",
      "0.009999971601096055\n",
      "episode: 800/2000, score: 140.0, rewards : -1504.0\n",
      "0.009999971601096055\n",
      "episode: 801/2000, score: 200.0, rewards : -1413.0\n",
      "0.009999971601096055\n",
      "episode: 802/2000, score: 140.0, rewards : -1468.0\n",
      "0.009999971601096055\n",
      "episode: 803/2000, score: 220.0, rewards : -1558.0\n",
      "0.009999971601096055\n",
      "episode: 804/2000, score: 240.0, rewards : -1530.0\n",
      "0.009999971601096055\n",
      "episode: 805/2000, score: 240.0, rewards : -1481.0\n",
      "0.009999971601096055\n",
      "episode: 806/2000, score: 240.0, rewards : -1395.0\n",
      "0.009999971601096055\n",
      "episode: 807/2000, score: 140.0, rewards : -1469.0\n",
      "0.009999971601096055\n",
      "episode: 808/2000, score: 240.0, rewards : -1497.0\n",
      "0.009999971601096055\n",
      "episode: 809/2000, score: 140.0, rewards : -1476.0\n",
      "0.009999971601096055\n",
      "episode: 810/2000, score: 100.0, rewards : -1563.0\n",
      "0.009999971601096055\n",
      "episode: 811/2000, score: 240.0, rewards : -1612.0\n",
      "0.009999971601096055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 812/2000, score: 210.0, rewards : -1533.0\n",
      "0.009999971601096055\n",
      "episode: 813/2000, score: 140.0, rewards : -1460.0\n",
      "0.009999971601096055\n",
      "episode: 814/2000, score: 240.0, rewards : -1554.0\n",
      "0.009999971601096055\n",
      "episode: 815/2000, score: 140.0, rewards : -1479.0\n",
      "0.009999971601096055\n",
      "episode: 816/2000, score: 210.0, rewards : -1542.0\n",
      "0.009999971601096055\n",
      "episode: 817/2000, score: 210.0, rewards : -1462.0\n",
      "0.009999971601096055\n",
      "episode: 818/2000, score: 200.0, rewards : -1575.0\n",
      "0.009999971601096055\n",
      "episode: 819/2000, score: 240.0, rewards : -1546.0\n",
      "0.009999971601096055\n",
      "episode: 820/2000, score: 170.0, rewards : -1716.0\n",
      "0.009999971601096055\n",
      "episode: 821/2000, score: 240.0, rewards : -1485.0\n",
      "0.009999971601096055\n",
      "episode: 822/2000, score: 120.0, rewards : -1525.0\n",
      "0.009999971601096055\n",
      "episode: 823/2000, score: 240.0, rewards : -1646.0\n",
      "0.009999971601096055\n",
      "episode: 824/2000, score: 240.0, rewards : -1461.0\n",
      "0.009999971601096055\n",
      "episode: 825/2000, score: 240.0, rewards : -1625.0\n",
      "0.009999971601096055\n",
      "episode: 826/2000, score: 210.0, rewards : -1446.0\n",
      "0.009999971601096055\n",
      "episode: 827/2000, score: 160.0, rewards : -1507.0\n",
      "0.009999971601096055\n",
      "episode: 828/2000, score: 170.0, rewards : -1488.0\n",
      "0.009999971601096055\n",
      "episode: 829/2000, score: 140.0, rewards : -1493.0\n",
      "0.009999971601096055\n",
      "episode: 830/2000, score: 140.0, rewards : -1498.0\n",
      "0.009999971601096055\n",
      "episode: 831/2000, score: 170.0, rewards : -1522.0\n",
      "0.009999971601096055\n",
      "episode: 832/2000, score: 190.0, rewards : -1500.0\n",
      "0.009999971601096055\n",
      "episode: 833/2000, score: 170.0, rewards : -1528.0\n",
      "0.009999971601096055\n",
      "episode: 834/2000, score: 150.0, rewards : -1587.0\n",
      "0.009999971601096055\n",
      "episode: 835/2000, score: 240.0, rewards : -1629.0\n",
      "0.009999971601096055\n",
      "episode: 836/2000, score: 170.0, rewards : -1705.0\n",
      "0.009999971601096055\n",
      "episode: 837/2000, score: 210.0, rewards : -1548.0\n",
      "0.009999971601096055\n",
      "episode: 838/2000, score: 230.0, rewards : -1577.0\n",
      "0.009999971601096055\n",
      "episode: 839/2000, score: 170.0, rewards : -1738.0\n",
      "0.009999971601096055\n",
      "episode: 840/2000, score: 230.0, rewards : -1632.0\n",
      "0.009999971601096055\n",
      "episode: 841/2000, score: 70.0, rewards : -1621.0\n",
      "0.009999971601096055\n",
      "episode: 842/2000, score: 140.0, rewards : -1562.0\n",
      "0.009999971601096055\n",
      "episode: 843/2000, score: 70.0, rewards : -1637.0\n",
      "0.009999971601096055\n",
      "episode: 844/2000, score: 140.0, rewards : -1470.0\n",
      "0.009999971601096055\n",
      "episode: 845/2000, score: 140.0, rewards : -1721.0\n",
      "0.009999971601096055\n",
      "episode: 846/2000, score: 130.0, rewards : -1578.0\n",
      "0.009999971601096055\n",
      "episode: 847/2000, score: 110.0, rewards : -1579.0\n",
      "0.009999971601096055\n",
      "episode: 848/2000, score: 240.0, rewards : -1584.0\n",
      "0.009999971601096055\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d9f1cb3eb2bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MsPacman-ram-v0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m \u001b[0msum_of_rewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-d9f1cb3eb2bd>\u001b[0m in \u001b[0;36mlearning\u001b[1;34m(env, episodes, params)\u001b[0m\n\u001b[0;32m     94\u001b[0m           \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'batch_size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m               \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp_replay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;31m#               print(f'final state before dying: {str(state)}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-d9f1cb3eb2bd>\u001b[0m in \u001b[0;36mexp_replay\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mminibatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mrewards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from collections import deque \n",
    "import random\n",
    "class DQN:\n",
    "\n",
    "  \"\"\" Deep Q Network \"\"\"\n",
    "\n",
    "  def __init__(self, env, params):\n",
    "\n",
    "      self.action_space = env.action_space.n\n",
    "      self.state_space = env.observation_space.shape[0]\n",
    "      self.epsilon = params['epsilon']                  # epsilon greedy exploration\n",
    "      self.gamma = params['gamma']                      # discount factor\n",
    "      self.batch_size = params['batch_size']            # experience replay batch size\n",
    "      self.epsilon_min = params['epsilon_min']          # min greedininess\n",
    "      self.epsilon_decay = params['epsilon_decay']      # decay factor for exploration\n",
    "      self.learning_rate = params['learning_rate']      # NN learning rate\n",
    "      self.layer_sizes = params['layer_sizes']          # NN architecture\n",
    "      self.memory = deque(maxlen=2500)                  # maximum memory for experinece replay\n",
    "      self.model = self.build_model()                   \n",
    "\n",
    "\n",
    "  def build_model(self):\n",
    "      model = Sequential()\n",
    "      for i in range(len(self.layer_sizes)):\n",
    "          if i == 0:\n",
    "              model.add(Dense(self.layer_sizes[i], input_shape=(self.state_space,), activation='relu'))\n",
    "          else:\n",
    "              model.add(Dense(self.layer_sizes[i], activation='relu'))\n",
    "      model.add(Dense(self.action_space, activation='softmax'))\n",
    "      model.compile(loss='mse', optimizer=Adam(lr=self.learning_rate))\n",
    "      return model\n",
    "\n",
    "\n",
    "  def remember(self, state, action, reward, next_state, done):\n",
    "    # create dataet for xperience replay\n",
    "      self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "  def act(self, state):\n",
    "      #  epsilon greedy policy\n",
    "      if np.random.rand() <= self.epsilon:\n",
    "          return random.randrange(self.action_space)\n",
    "      act_values = self.model.predict(state)\n",
    "      return np.argmax(act_values[0])\n",
    "\n",
    "\n",
    "  def exp_replay(self):\n",
    "    if len(self.memory)<self.batch_size:\n",
    "      return\n",
    "    minibatch = random.sample(self.memory, self.batch_size)\n",
    "    states = np.array([i[0] for i in minibatch])\n",
    "    actions = np.array([i[1] for i in minibatch])\n",
    "    rewards = np.array([i[2] for i in minibatch])\n",
    "    next_states = np.array([i[3] for i in minibatch])\n",
    "    dones = np.array([i[4] for i in minibatch])\n",
    "    \n",
    "    states = np.squeeze(states)\n",
    "    next_states = np.squeeze(next_states)\n",
    "\n",
    "    targets_pred = self.model.predict_on_batch(states)\n",
    "    targets_act = rewards + self.gamma*((np.amax(self.model.predict_on_batch(next_states), axis=1))*(1-dones))\n",
    "\n",
    "    ind = np.array([i for i in range(self.batch_size)])\n",
    "    targets_full = targets_pred\n",
    "    targets_full[[ind], [actions]] = targets_act\n",
    "\n",
    "    self.model.fit(states, targets_full, epochs=1, verbose=0)\n",
    "    if self.epsilon > self.epsilon_min:\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "\n",
    "\n",
    "def learning(env,episodes, params):\n",
    "\n",
    "  sum_of_rewards = []\n",
    "  output = []\n",
    "  agent = DQN(env, params)\n",
    "  for ep in range(episodes):\n",
    "      state = env.reset()\n",
    "      state = np.reshape(state, (1, env.observation_space.shape[0]))\n",
    "      score = 0\n",
    "      tot_reward = 0\n",
    "      max_steps = 100000\n",
    "      while True:\n",
    "          action = agent.act(state)\n",
    "          next_state, reward, done, _ = env.step(action)\n",
    "          points = reward\n",
    "          reward -=1\n",
    "          if done == True:\n",
    "                reward = -1000\n",
    "#           env.render(mode = 'human')\n",
    "          tot_reward += reward\n",
    "          score += points\n",
    "          next_state = np.reshape(state, (1, env.observation_space.shape[0]))\n",
    "          agent.remember(state, action, reward, next_state, done)\n",
    "          if params['batch_size'] > 1:\n",
    "              agent.exp_replay()\n",
    "          if done:\n",
    "#               print(f'final state before dying: {str(state)}')\n",
    "              print(f'episode: {ep+1}/{episodes}, score: {score}, rewards : {tot_reward}')\n",
    "              print(agent.epsilon)\n",
    "              break\n",
    "          state = next_state\n",
    "      sum_of_rewards.append(score)\n",
    "      agent.model.save('model')\n",
    "      agent.model.save_weights('weights')\n",
    "  env.close()\n",
    "  return sum_of_rewards, output\n",
    "\n",
    "\n",
    "params = dict()\n",
    "params['name'] = None\n",
    "params['epsilon'] = 1\n",
    "params['gamma'] = 0.8\n",
    "params['batch_size'] = 512\n",
    "params['epsilon_min'] = 0.01\n",
    "params['epsilon_decay'] = .99999\n",
    "params['learning_rate'] = 0.01\n",
    "params['layer_sizes'] = [64, 32, 16]\n",
    "\n",
    "results = dict()\n",
    "ep = 2000\n",
    "\n",
    "\n",
    "# env_infos = {'States: only walls':{'state_space':'no body knowledge'}, 'States: direction 0 or 1':{'state_space':''}, 'States: coordinates':{'state_space':'coordinates'}, 'States: no direction':{'state_space':'no direction'}}\n",
    "\n",
    "env = gym.make('MsPacman-ram-v0')\n",
    "sum_of_rewards, output = learning(env, ep, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3YoH3LVHCHx",
    "outputId": "31ea4af8-02ef-41d7-dd4f-2cdcd3380cf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('MsPacman-ram-v0')\n",
    "\n",
    "env.action_space.n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Q-learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
